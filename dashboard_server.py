import os
import glob
import pandas as pd
from flask import Flask, jsonify, render_template, abort, send_from_directory, request, send_file
from pathlib import Path
import webbrowser
from threading import Timer
import io
import tempfile
from datetime import datetime
import zipfile
import threading
import html
import re
import hashlib
import shutil

# Check for required dependencies

try:
    from reportlab.lib.pagesizes import A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
    from reportlab.platypus import Image as ReportLabImage
    from reportlab.lib.styles import getSampleStyleSheet
    from reportlab.lib import colors
    from reportlab.lib.units import mm
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.pdfbase.cidfonts import UnicodeCIDFont
    REPORTLAB_AVAILABLE = True
except ImportError:
    print("âš ï¸ Warning: ReportLab not installed. PDF export will be disabled.")
    REPORTLAB_AVAILABLE = False

try:
    import matplotlib
    matplotlib.use('Agg')  # Use non-interactive backend
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    print("âš ï¸ Warning: Matplotlib not installed. Charts in PDF will be disabled.")
    MATPLOTLIB_AVAILABLE = False

try:
    from PIL import Image as PILImage, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    print("âš ï¸ Warning: PIL/Pillow not installed. Image processing will be disabled.")
    PIL_AVAILABLE = False

# Optional: Playwright for HTML thumbnail rendering
try:
    from playwright.sync_api import sync_playwright
    PLAYWRIGHT_AVAILABLE = True
    print("âœ… Playwright available for HTML thumbnail generation")
except Exception as e:
    print("âš ï¸ Warning: Playwright not available. HTML thumbnail generatio   cn disabled.")
    print(f"   To enable: pip install playwright && playwright install chromium")
    PLAYWRIGHT_AVAILABLE = False

# Check if we have the minimum requirements for thumbnails
THUMBNAIL_CAPABLE = PIL_AVAILABLE or PLAYWRIGHT_AVAILABLE
if not THUMBNAIL_CAPABLE:
    print("âŒ Warning: No thumbnail generation capability available!")
    print("   Install either PIL/Pillow or Playwright for thumbnail support")
else:
    print("âœ… Thumbnail generation capability available")

# --- Chrome Path Configuration for Playwright ---
# à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² Playwright browsers path à¹ƒà¸«à¹‰à¸Šà¸µà¹‰à¹„à¸›à¸—à¸µà¹ˆ chrome-win à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§
chrome_path = Path(__file__).resolve().parent / "chrome-win"
os.environ.setdefault("PLAYWRIGHT_BROWSERS_PATH", str(chrome_path))
print(f"âœ… Chrome path configured: {chrome_path}")

app = Flask(__name__)

# --- Configuration ---
# The directory of this server script
SERVER_DIR = Path(__file__).parent.resolve()
# The project root is two levels up (from /Test Dashboard/Dashboard_Report)
PROJECT_ROOT = SERVER_DIR.parent.parent

# Helper function for timestamp validation (moved here to be available for discovery)
def is_valid_timestamp_folder(folder_name):
    """Check if folder name is a valid timestamp format (YYYYMMDD-HHMMSS or YYYYMMDD_HHMMSS)."""
    if len(folder_name) != 15:
        return False
    
    # Check for valid separators at position 8
    if folder_name[8] not in ['-', '_']:
        return False
    
    # Check if date and time parts are digits
    date_part = folder_name[:8]
    time_part = folder_name[9:]
    
    return date_part.isdigit() and time_part.isdigit()

def discover_results_directory():
    """
    Auto-discover results directory by searching for 'results' folders in project subdirectories.
    This makes the system flexible to work with any project structure.
    
    Search order:
    1. Environment variable RESULTS_DIR (if set)
    2. Search for 'results' folders in PROJECT_ROOT subdirectories (1 level deep)
    3. Fallback to PROJECT_ROOT / "results" (if exists)
    
    Returns the first valid results directory found.
    """
    # 1. Check environment variable first (manual override)
    env_results_dir = os.environ.get('RESULTS_DIR')
    if env_results_dir:
        env_path = Path(env_results_dir)
        if env_path.exists() and env_path.is_dir():
            print(f"âœ… Using RESULTS_DIR from environment: {env_path}")
            return env_path
        else:
            print(f"âš ï¸ Environment RESULTS_DIR not found: {env_path}")
    
    # 2. Auto-discover by searching project subdirectories (1 level deep)
    print(f"ðŸ” Auto-discovering results directory in: {PROJECT_ROOT}")
    
    # List all subdirectories in PROJECT_ROOT
    project_subdirs = [d for d in PROJECT_ROOT.iterdir() if d.is_dir() and not d.name.startswith('.')]
    print(f"ðŸ“‚ Found project subdirectories: {[d.name for d in project_subdirs]}")
    
    # Look for 'results' folder in each project subdirectory
    for subdir in project_subdirs:
        results_candidate = subdir / "results"
        if results_candidate.exists() and results_candidate.is_dir():
            # Check if this results directory contains valid timestamp folders
            timestamp_dirs = [d for d in results_candidate.iterdir() 
                            if d.is_dir() and is_valid_timestamp_folder(d.name)]
            
            if timestamp_dirs:
                print(f"âœ… Found valid results directory: {results_candidate}")
                print(f"ðŸ“Š Contains {len(timestamp_dirs)} timestamp folders")
                return results_candidate
            else:
                print(f"ðŸ“ Found results folder but no valid timestamp data: {results_candidate}")
    
    # 3. Fallback to PROJECT_ROOT/results (direct under project root)
    fallback_results = PROJECT_ROOT / "results"
    if fallback_results.exists() and fallback_results.is_dir():
        print(f"âœ… Using fallback results directory: {fallback_results}")
        return fallback_results
    
    # 4. Create a default results directory if none found
    default_results = PROJECT_ROOT / "results"
    print(f"âš ï¸ No results directory found. Creating default: {default_results}")
    default_results.mkdir(exist_ok=True)
    return default_results

# Auto-discover results directory
RESULTS_DIR = discover_results_directory()

# ============================================================================
# UTILITY CLASSES AND CONSTANTS
# ============================================================================

# Column name constants for Excel file parsing
COLUMN_NAMES = {
    'test_case': ['TestCaseNo', 'Test Case No', 'TestCase', 'TC', 'Test Case'],
    'result_folder': ['ResultFolder', 'Result Folder', 'Folder', 'Path'],
    'status': ['TestResult', 'Status', 'Result'],
    'execute': ['Execute'],
    'description': ['Test Case Description', 'TestCaseDescription', 'Description', 'Test Description', 'Name', 'TestCaseDesc'],
    'error': ['Fail_Description', 'Fail Description', 'TestResult Description', 'Result Description', 'Error', 'Message', 'Failure Reason'],
    'expected': ['ExpectedResult', 'Expected Result', 'Expected', 'Expected Outcome'],
}


class ExcelColumnFinder:
    """Utility to find columns by multiple possible names."""
    
    @staticmethod
    def find_column(df, candidates, case_sensitive=True):
        """Find first matching column from candidates.
        
        Args:
            df: pandas DataFrame
            candidates: List of possible column names
            case_sensitive: Whether to match case-sensitively
            
        Returns:
            Column name if found, None otherwise
        """
        for col in candidates:
            if case_sensitive:
                if col in df.columns:
                    return col
            else:
                for df_col in df.columns:
                    if df_col.lower() == col.lower():
                        return df_col
        return None
    
    @staticmethod
    def find_multiple(df, columns_dict):
        """Find multiple columns at once.
        
        Args:
            df: pandas DataFrame
            columns_dict: Dictionary {key: [candidate1, candidate2, ...]}
            
        Returns:
            Dictionary {key: found_column_name or None}
        """
        results = {}
        for key, candidates in columns_dict.items():
            results[key] = ExcelColumnFinder.find_column(df, candidates)
        return results


class ExcelRowAccessor:
    """Wrapper for accessing row data from pandas Series or dict."""
    
    def __init__(self, row):
        """Initialize with a row (pandas Series or dict)."""
        self.row = row
        try:
            self.available_fields = list(
                getattr(row, 'index', getattr(row, 'keys', lambda: [])())
            )
        except Exception:
            self.available_fields = []
    
    def get(self, key, default=None):
        """Get value from row by key.
        
        Args:
            key: Column name to retrieve
            default: Default value if key not found
            
        Returns:
            Value from row or default
        """
        try:
            if key is None:
                return default
            if hasattr(self.row, 'get'):
                return self.row.get(key, default)
            return self.row[key] if key in self.available_fields else default
        except Exception:
            return default
    
    def pick_column(self, candidates):
        """Find first available column from candidates.
        
        Args:
            candidates: List of possible column names
            
        Returns:
            First found column name or None
        """
        for c in candidates:
            if c in self.available_fields:
                return c
        return None
    
    def get_by_candidates(self, candidates, default=None):
        """Get value using first available column from candidates.
        
        Args:
            candidates: List of possible column names
            default: Default value if no column found
            
        Returns:
            Value from first found column or default
        """
        col = self.pick_column(candidates)
        return self.get(col, default)


class PathNormalizer:
    """Utility for normalizing file paths across the application."""
    
    @staticmethod
    def to_relative(absolute_path, base_path):
        """Convert absolute path to relative from base.
        
        Args:
            absolute_path: Path to convert
            base_path: Base path to make relative to
            
        Returns:
            Relative path string with forward slashes, or None if conversion fails
        """
        try:
            return str(Path(absolute_path).relative_to(base_path)).replace("\\", "/")
        except ValueError:
            return None
    
    @staticmethod
    def normalize_evidence_path(path_str):
        """Normalize evidence path for API serving.
        
        Args:
            path_str: Path string to normalize
            
        Returns:
            Normalized path with /results/ prefix and forward slashes
        """
        path = path_str.strip()
        # Remove optional 'Automation Project/' prefix
        if path.startswith('Automation Project/'):
            path = path.replace('Automation Project/', '', 1)
        # Ensure /results/ prefix
        if not path.startsWith('/results/'):
            path = '/results/' + path.lstrip('/')
        return path.replace('\\', '/')


def normalize_test_status(status_series):
    """Normalize test status values to standard format.
    
    Args:
        status_series: pandas Series with status values
        
    Returns:
        pandas Series with normalized lowercase status values
    """
    # Fill NaN and convert to string
    normalized = status_series.fillna('').astype(str).str.strip()
    
    # Normalization mapping
    status_mapping = {
        r"^failed$": "fail",
        r"^FAILED$": "fail",
        r"^Failed$": "fail",
        r"^fail\s*\(\s*major\s*\)$": "fail (major)",
        r"^failed\s*\(\s*major\s*\)$": "fail (major)",
        r"^FAIL\s*\(\s*MAJOR\s*\)$": "fail (major)",
        r"^fail\s*\(\s*block\s*\)$": "fail (block)",
        r"^failed\s*\(\s*block\s*\)$": "fail (block)",
        r"^FAIL\s*\(\s*BLOCK\s*\)$": "fail (block)",
        r"^FAIL\s*MAJOR$": "fail (major)",
        r"^FAIL\s*BLOCK$": "fail (block)",
        r"^FAIL\(MAJOR\)$": "fail (major)",
        r"^FAIL\(BLOCK\)$": "fail (block)"
    }
    
    normalized = normalized.replace(status_mapping, regex=True)
    return safe_str_lower(normalized)

# ============================================================================
# END UTILITY CLASSES
# ============================================================================

# PDF font configuration (try Unicode CID fonts first, then fallback to local/system Thai TTFs)
PDF_FONT_NORMAL = 'Helvetica'
PDF_FONT_BOLD = 'Helvetica-Bold'

def setup_unicode_cid_fonts() -> bool:
    """Try to register Unicode CID fonts that support Thai without external TTF files."""
    global PDF_FONT_NORMAL, PDF_FONT_BOLD
    if not REPORTLAB_AVAILABLE:
        return False
    try:
        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
        
        # IMPORTANT: Update global variables using globals() to ensure they persist
        globals()['PDF_FONT_NORMAL'] = 'HeiseiMin-W3'
        globals()['PDF_FONT_BOLD'] = 'HeiseiKakuGo-W5'
        
        print(f'[INFO] Using Unicode CID fonts: HeiseiMin-W3 / HeiseiKakuGo-W5')
        print(f'[DEBUG] Global vars updated: Normal={globals()["PDF_FONT_NORMAL"]}, Bold={globals()["PDF_FONT_BOLD"]}')
        
        return True
    except Exception as e:
        print(f'[WARN] Unicode CID fonts not available: {e}')
        return False

def _try_register_font(font_name: str, ttf_path: Path) -> bool:
    """Helper to register a font."""
    try:
        if ttf_path and ttf_path.exists():
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            
            pdfmetrics.registerFont(TTFont(font_name, str(ttf_path)))
            print(f"[REGISTERED] Font '{font_name}' from {ttf_path}")
            return True
    except Exception as e:
        print(f"[WARN] Could not register font {ttf_path}: {e}")
    return False

def verify_font_settings():
    """Verify current font settings."""
    print("\n" + "="*60)
    print("FONT VERIFICATION")
    print("="*60)
    print(f"PDF_FONT_NORMAL = {PDF_FONT_NORMAL}")
    print(f"PDF_FONT_BOLD = {PDF_FONT_BOLD}")
    
    if REPORTLAB_AVAILABLE:
        from reportlab.pdfbase import pdfmetrics
        
        # Check if fonts are registered
        try:
            # Try to get font info
            normal_font = pdfmetrics.getFont(PDF_FONT_NORMAL)
            bold_font = pdfmetrics.getFont(PDF_FONT_BOLD)
            print(f"âœ… Normal font registered: {normal_font}")
            print(f"âœ… Bold font registered: {bold_font}")
        except Exception as e:
            print(f"âŒ Font not properly registered: {e}")
    
    # Check if Thai fonts
    is_thai = not (PDF_FONT_NORMAL == 'Helvetica' or PDF_FONT_BOLD == 'Helvetica-Bold')
    if is_thai:
        print("âœ… Thai fonts are active")
    else:
        print("âŒ Still using default Helvetica (no Thai support)")
    
    print("="*60 + "\n")
    return is_thai

def ensure_thai_fonts():
    """Ensure Thai fonts are available for PDF generation.

    This function now attempts to register built-in Unicode CID fonts (HeiseiMin/HeiseiKakuGo) before
    searching for external TTF files. If those CID fonts are available, the global font variables
    are updated and no further work is needed. Otherwise, it searches for common Thai fonts on the
    local filesystem and registers them. As a final fallback, it resets the fonts to Helvetica.
    """
    global PDF_FONT_NORMAL, PDF_FONT_BOLD

    # Bail out early if ReportLab isn't installed
    if not REPORTLAB_AVAILABLE:
        print("[ERROR] ReportLab not available!")
        return False

    # Keep the fonts if they've already been set to something other than the defaults
    if (PDF_FONT_NORMAL != 'Helvetica' and PDF_FONT_BOLD != 'Helvetica-Bold' and
        PDF_FONT_NORMAL != 'Helvetica-Bold' and PDF_FONT_BOLD != 'Helvetica'):
        print(f"âœ… Thai fonts already loaded: {PDF_FONT_NORMAL}, {PDF_FONT_BOLD}")
        return True

    # Step 1: Look for Thai fonts first (local/system TTFs).
    candidates = [
        ("THSarabunNew", "THSarabunNew.ttf", "THSarabunNew-Bold", "THSarabunNew Bold.ttf"),
        ("THSarabunNew", "THSarabunNew.ttf", "THSarabunNew-Bold", "THSarabunNew-Bold.ttf"),
        ("Sarabun", "Sarabun-Regular.ttf", "Sarabun-Bold", "Sarabun-Bold.ttf"),
        ("NotoSansThai", "NotoSansThai-Regular.ttf", "NotoSansThai-Bold", "NotoSansThai-Bold.ttf"),
    ]
    
    search_dirs = [
        SERVER_DIR / 'fonts',
        PROJECT_ROOT / 'fonts',
        Path('C:/Windows/Fonts'),
        Path('/usr/share/fonts'),
        Path('/usr/local/share/fonts'),
        Path('/System/Library/Fonts'),
        Path.home() / '.fonts',
    ]
    
    print(f"[INFO] Searching for Thai fonts in: {[str(d) for d in search_dirs if d.exists()]}")
    
    for family_name, normal_file, bold_name, bold_file in candidates:
        normal_path = None
        bold_path = None
        
        for d in search_dirs:
            if not d.exists():
                continue
                
            if not normal_path:
                p = d / normal_file
                if p.exists():
                    normal_path = p
                    print(f"[FOUND] Normal font: {normal_path}")
            
            if not bold_path:
                p = d / bold_file
                if p.exists():
                    bold_path = p
                    print(f"[FOUND] Bold font: {bold_path}")
                # Try without space
                elif not bold_path:
                    alt_bold = d / bold_file.replace(" ", "")
                    if alt_bold.exists():
                        bold_path = alt_bold
                        print(f"[FOUND] Bold font (alt): {bold_path}")
        
        if normal_path and bold_path:
            norm_reg_name = f"{family_name}-Regular"
            bold_reg_name = f"{family_name}-Bold"
            
            if _try_register_font(norm_reg_name, normal_path) and \
               _try_register_font(bold_reg_name, bold_path):
                # IMPORTANT: Set the global variables using globals() to ensure they persist
                globals()['PDF_FONT_NORMAL'] = norm_reg_name
                globals()['PDF_FONT_BOLD'] = bold_reg_name
                
                print(f"[SUCCESS] âœ… Registered Thai fonts: {family_name}")
                print(f"  Normal: {globals()['PDF_FONT_NORMAL']} -> {normal_path}")
                print(f"  Bold: {globals()['PDF_FONT_BOLD']} -> {bold_path}")
                
                # Double check the values
                print(f"[VERIFY] Global vars: Normal={globals()['PDF_FONT_NORMAL']}, Bold={globals()['PDF_FONT_BOLD']}")
                
                return True
    
    # If still no Thai fonts found locally, try built-in CID fonts as a fallback.
    try:
        if setup_unicode_cid_fonts():
            return True
    except Exception as e:
        print(f"âš ï¸ Could not register CID fonts: {e}")

    # If nothing works, warn and keep Helvetica (no Thai support)
    print("[WARNING] âš ï¸ No Thai fonts found! Using Helvetica (no Thai support)")
    return False

def escape_html_for_pdf(text):
    """
    Safely escape HTML/XML characters for use in ReportLab Paragraphs.
    Also handles very long text by adding soft breaks.
    Specially optimized for Thai text and very long content (10,000+ characters).
    """
    if not text or text in ['nan', 'none', '', 'None']:
        return ''
    
    # Convert to string and strip
    text = str(text).strip()
    
    # Log text statistics for debugging
    text_length = len(text)
    has_thai = any(ord(c) > 127 for c in text)
    print(f"[DEBUG] Processing text for PDF: length={text_length}, has_non_ascii={has_thai}")
    
    # For extremely long text (>10,000 chars), truncate with warning
    if text_length > 10000:
        print(f"[WARNING] Very long text detected ({text_length} chars), truncating to 10,000 characters")
        text = text[:10000] + "... [à¹€à¸™à¸·à¹‰à¸­à¸«à¸²à¸–à¸¹à¸à¸•à¸±à¸”à¸—à¸­à¸™à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸¡à¸µà¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸¡à¸²à¸]"
    
    # Escape HTML/XML characters
    text = html.escape(text)
    
    # Handle very long lines by adding soft breaks
    # Use shorter line length for Thai text as it tends to be more dense
    max_line_length = 80 if has_thai else 100
    
    lines = text.split('\n')
    processed_lines = []
    
    for line in lines:
        if len(line) > max_line_length:
            # For Thai text, break more frequently as word boundaries are harder to detect
            if has_thai:
                # Break Thai text every 80 characters regardless of word boundaries
                for i in range(0, len(line), max_line_length):
                    chunk = line[i:i + max_line_length]
                    processed_lines.append(chunk)
            else:
                # For English text, try to preserve word boundaries
                words = line.split(' ')
                current_line = []
                current_length = 0
                
                for word in words:
                    if current_length + len(word) + 1 > max_line_length and current_line:
                        processed_lines.append(' '.join(current_line))
                        current_line = [word]
                        current_length = len(word)
                    else:
                        current_line.append(word)
                        current_length += len(word) + 1
                
                if current_line:
                    processed_lines.append(' '.join(current_line))
        else:
            processed_lines.append(line)
    
    result = '<br/>'.join(processed_lines)
    print(f"[DEBUG] Text processing completed: original_length={text_length}, processed_length={len(result)}, lines={len(processed_lines)}")
    return result

# --- Helper Functions ---
def sanitize_filename(name: str, replacement: str = "_") -> str:
    """Return a filesystem and header safe filename.
    Removes characters invalid on Windows or HTTP headers and collapses repeats.
    """
    if name is None:
        return "file"
    text = str(name)
    # Remove path separators and illegal characters: \\/:*?"<>| and control chars
    illegal_chars = "\\/:*?\"<>|\r\n\t"
    for ch in illegal_chars:
        text = text.replace(ch, replacement)
    # Also guard against commas and semicolons in headers
    for ch in [',', ';']:
        text = text.replace(ch, replacement)
    # Collapse repeats of replacement
    while replacement * 2 in text:
        text = text.replace(replacement * 2, replacement)
    text = text.strip().strip('.')
    return text or "file"

def extract_timestamp_from_path(path_obj):
    """Extract timestamp from path, keeping original format."""
    try:
        # Try path parts first
        for part in path_obj.parts:
            if is_valid_timestamp_folder(part):
                return part  # Keep original format
        
        # Try filename parts if not found in path
        filename_parts = path_obj.stem.split('_')
        for part in filename_parts:
            if is_valid_timestamp_folder(part):
                return part  # Keep original format
                
        return "unknown"
    except Exception as e:
        print(f"Error extracting timestamp from {path_obj}: {e}")
        return "unknown"



def find_excel_files(base_dir):
    """Finds all relevant feature excel files in valid timestamp directories only."""
    try:
        if not base_dir.exists() or not base_dir.is_dir():
            print(f"Results directory not found: {base_dir}")
            return []
        
        valid_excel_paths = []
        
        # Iterate through direct subdirectories of results
        for item in base_dir.iterdir():
            if item.is_dir():
                # Only process directories with valid timestamp format
                if is_valid_timestamp_folder(item.name):
                    print(f"[DEBUG] Processing valid timestamp folder: {item.name}")
                    # Search for .xlsx files in this valid timestamp directory
                    excel_paths = glob.glob(str(item / "*.xlsx"))
                    valid_excel_paths.extend(excel_paths)
                else:
                    print(f"[DEBUG] Ignoring invalid timestamp folder: {item.name}")
        
        return sorted(valid_excel_paths, reverse=True)
    except Exception as e:
        print(f"Error finding Excel files: {e}")
        return []

def safe_str_lower(series):
    """Safely convert series to lowercase, handling NaN values."""
    try:
        if hasattr(series, 'fillna'):
            return series.fillna('').astype(str).str.lower()
        else:
            return pd.Series(series).fillna('').astype(str).str.lower()
    except Exception:
        return pd.Series(series).fillna('').astype(str).str.lower()

def find_first_column(headers, candidates):
    """Return the first column name found from candidates list (case-sensitive as Excel provides), or None."""
    for name in candidates:
        if name in headers:
            return name
    return None

def filter_executed_rows(df):
    """Return DataFrame filtered by Execute == 'Y' if column exists; otherwise original df."""
    try:
        execute_column = next((c for c in df.columns if c.lower() == 'execute'), None)
        if execute_column:
            temp = df.copy()
            temp[execute_column] = temp[execute_column].fillna('')
            return temp[temp[execute_column].astype(str).str.lower() == 'y'].copy()
        return df
    except Exception:
        return df

def get_row_by_id(df, id_candidates, target_id):
    """Return the row that matches target_id using the first available id column. Exact match only; None if not found."""
    id_col = find_first_column(df.columns, id_candidates)
    if not id_col:
        return None
    for _, row in df.iterrows():
        row_id = str(row.get(id_col, '')).strip()
        if row_id == str(target_id).strip():
            return row
    return None

def get_test_case_description(excel_path, test_case_id):
    """
    Extracts test case description from Excel file based on test case ID.
    Returns the description or None if not found.
    """
    try:
        if not Path(excel_path).exists():
            print(f"Excel file not found: {excel_path}")
            return None
            
        df = pd.read_excel(excel_path, sheet_name="MAIN")
        try:
            print(f"[DEBUG][Excel Load] path={excel_path} rows={len(df)} cols={len(df.columns)} headers={list(df.columns)}")
        except Exception:
            pass
        
        if df.empty:
            return None
        
        # Use utility to find test case ID and description columns
        id_col = ExcelColumnFinder.find_column(df, COLUMN_NAMES['TestCaseNo'])
        desc_col = ExcelColumnFinder.find_column(df, COLUMN_NAMES['TestCaseDesc'])
        
        if id_col and desc_col:
            # Normalize for matching
            test_case_id_str = str(test_case_id).strip()
            df[id_col] = df[id_col].fillna('').astype(str)
            norm_series = df[id_col].str.strip().str.casefold()
            target = test_case_id_str.casefold()

            # 1) Exact match first (case-insensitive)
            exact_mask = norm_series == target
            if exact_mask.any():
                row = df[exact_mask].iloc[0]
                desc_value = row.get(desc_col, '')
                return str(desc_value) if pd.notna(desc_value) and str(desc_value).strip() else None

            # 2) Fuzzy fallback: startswith id (e.g., TC001_1234)
            starts_mask = norm_series.str.startswith(target + '_') | norm_series.str.startswith(target + '-')
            if starts_mask.any():
                row = df[starts_mask].iloc[0]
                desc_value = row.get(desc_col, '')
                return str(desc_value) if pd.notna(desc_value) and str(desc_value).strip() else None
        
        return None
    except Exception as e:
        print(f"Error getting test case description for {test_case_id} from {excel_path}: {e}")
        return None

def parse_excel_data(excel_path):
    """
    Parses a single feature's Excel file to extract summary data.
    Returns a dictionary with summary, or None on error.
    """
    try:
        excel_path_obj = Path(excel_path)
        if not excel_path_obj.exists():
            print(f"Excel file not found: {excel_path}")
            return None
            
        df = pd.read_excel(excel_path)
        
        if df.empty:
            print(f"Empty Excel file: {excel_path}")
            return None
        
        # Use utility to find status column
        status_column = ExcelColumnFinder.find_column(df, COLUMN_NAMES['status'])
        
        if not status_column:
            print(f"No status column found in {excel_path}. Available columns: {df.columns.tolist()}")
            
            # Extract timestamp even for files without status column
            run_timestamp = extract_timestamp_from_path(excel_path_obj)
            
            # For files without status column, create a basic summary with 0 counts
            return {
                "feature_name": excel_path_obj.stem,
                "excel_path": str(excel_path_obj.relative_to(PROJECT_ROOT)).replace("\\", "/"),
                "total": 0,
                "passed": 0,
                "failed": 0,
                "pass_rate": 0,
                "status": "not_run",
                "run_timestamp": run_timestamp,
                "test_evidence": {},
                "image_files": []
            }

        # Use utility to find execute column
        execute_column = ExcelColumnFinder.find_column(df, COLUMN_NAMES['execute'], case_sensitive=False)
                
        # Use common filter helper
        executable_df = filter_executed_rows(df)
        try:
            print(f"[DEBUG][Execute Filter] execute_col={execute_column} before={len(df)} after={len(executable_df)}")
            # Debug the raw status values before processing
            if status_column and status_column in executable_df.columns:
                raw_statuses = executable_df[status_column].fillna('').astype(str).tolist()
                print(f"[DEBUG][Raw Status Values] raw_statuses={raw_statuses}")
        except Exception:
            pass

        if executable_df.empty:
            print(f"No executable tests found in {excel_path}")
            return None

        # Count passed and failed tests from the executable set (case insensitive)
        # Handle potential empty cells in status column gracefully
        executable_df = executable_df.copy()
        if status_column in executable_df.columns:
            # Use utility function for status normalization
            status_lower = normalize_test_status(executable_df[status_column])
        else:
            status_lower = pd.Series(dtype=str)
        
        # Only count tests that have Execute = 'Y' AND TestResult is either 'pass' or 'fail'
        # Tests with empty/null/other status values should not be counted in total
        # Count passed and failed tests (including Major and Blocker)
        pass_mask = status_lower == 'pass'
        fail_major_mask = status_lower == 'fail (major)'
        fail_blocker_mask = status_lower == 'fail (block)'
        fail_legacy_mask = status_lower == 'fail'  # Legacy 'fail' status
        
        # Combine all failure types
        fail_mask = fail_major_mask | fail_blocker_mask | fail_legacy_mask
        
        passed = int(pass_mask.sum())
        failed_major = int(fail_major_mask.sum()) + int(fail_legacy_mask.sum())  # Legacy 'fail' counts as Major
        failed_blocker = int(fail_blocker_mask.sum())
        failed = failed_major + failed_blocker
        total = passed + failed
        try:
            print(f"[DEBUG][Status Count] status_col={status_column} total={total} passed={passed} failed={failed}")
            print(f"[DEBUG][Detailed Count] fail_major_exact={int(fail_major_mask.sum())} fail_legacy_exact={int(fail_legacy_mask.sum())} fail_blocker_exact={int(fail_blocker_mask.sum())}")
            print(f"[DEBUG][Final Count] failed_major={failed_major} failed_blocker={failed_blocker}")
            # Show actual status values for debugging
            unique_statuses = status_lower.unique() if not status_lower.empty else []
            print(f"[DEBUG][Status Values] unique_statuses={list(unique_statuses)}")
        except Exception:
            pass
        
        pass_rate = (passed / total * 100) if total > 0 else 0
        
        # Determine status: only "passed" if there are actually executed tests with valid results and no failures
        if total == 0:
            status = "not_run"  # No tests were executed with valid pass/fail results
        elif failed == 0:
            status = "passed"   # All valid tests passed
        else:
            # Determine specific failure type
            if failed_blocker > 0:
                status = "failed_blocker"   # Has blocker failures
            else:
                status = "failed_major"     # Has major failures only
        
        # Extract feature name from filename first (needed for evidence filtering)
        filename = excel_path_obj.stem  # à¹€à¸Šà¹ˆà¸™ "DRDB_Payment_Output_20250516-161132"
        
        # à¸”à¸¶à¸‡ feature name à¸ˆà¸²à¸à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ
        # base = os.path.basename(filename)
        # if len(parts) >= 3 and parts[2] == "Output":
        #     parts = base.split("_")
        #     if len(parts) >= 3:
        #         feature_name = parts[1]
        #     else:
        #         feature_name = "TestResults"  # fallback
        # else:
        #     feature_name = "TestResults"  # fallback

        base = os.path.basename(filename)
        name_wo_ext = os.path.splitext(base)[0]  # à¸•à¸±à¸”à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥à¹„à¸Ÿà¸¥à¹Œà¸­à¸­à¸ à¹€à¸Šà¹ˆà¸™ .xlsx

        feature_name = "TestResults"  # fallback à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™

        # à¸•à¸±à¸”à¸”à¹‰à¸§à¸¢ "_" à¹€à¸žà¸·à¹ˆà¸­à¸„à¸‡à¸£à¸¹à¸›à¹à¸šà¸šà¹€à¸”à¸´à¸¡à¸‚à¸­à¸‡à¸—à¸µà¸¡
        tokens = name_wo_ext.split("_")

        # à¸žà¸¢à¸²à¸¢à¸²à¸¡à¸«à¸²à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸„à¸³à¸§à¹ˆà¸² "Output" à¹à¸šà¸šà¹„à¸¡à¹ˆà¸ªà¸™à¸•à¸±à¸§à¸žà¸´à¸¡à¸žà¹Œ
        out_idx = next((i for i, t in enumerate(tokens) if t.lower() == "output"), None)

        if out_idx is not None and out_idx >= 1:
            # à¸”à¸¶à¸‡ token à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸² "Output" à¹€à¸›à¹‡à¸™ feature_name
            feature_name = tokens[out_idx - 1]
        # else: à¸„à¸‡ fallback = "TestResults"

        
        print(f"[DEBUG] Extracted feature name from filename: {feature_name}")
        
        # NEW: Use ResultFolder column to collect evidence files
        excel_dir = excel_path_obj.parent  # This will be the timestamp folder (e.g., results/20250620_111221/)
        
        # Use utility to find ResultFolder and TestCaseNo columns
        result_folder_col = ExcelColumnFinder.find_column(df, COLUMN_NAMES['result_folder'])
        test_case_col = ExcelColumnFinder.find_column(df, COLUMN_NAMES['test_case'])
        
        if result_folder_col:
            print(f"[DEBUG] Found ResultFolder column: {result_folder_col}")
        if test_case_col:
            print(f"[DEBUG] Found TestCaseNo column: {test_case_col}")
        
        # Evidence file patterns
        evidence_patterns = ["*.png", "*.jpg", "*.jpeg", "*.gif", "*.bmp", "*.xlsx", "*.xls", "*.html", "*.htm"]
        
        # Build test_evidence by reading ResultFolder from each row
        test_evidence = {}
        
        if result_folder_col and test_case_col:
            print(f"[DEBUG] Using ResultFolder column to collect evidence files")
            # Iterate through rows with Execute='Y'
            for idx, row in df.iterrows():
                execute_val = str(row.get(execute_column, '')).strip().upper()
                if execute_val != 'Y':
                    continue
                
                test_case_id = str(row.get(test_case_col, '')).strip()
                result_folder = str(row.get(result_folder_col, '')).strip()
                
                # Skip if ResultFolder is empty
                if not result_folder or result_folder.lower() in ['nan', 'none', '']:
                    print(f"[DEBUG] Skipping {test_case_id}: No ResultFolder specified")
                    continue
                
                # Build full path: results/YYYYMMDD_HHMMSS/ResultFolder/
                # ResultFolder format: Payment\TC001_225522422
                result_folder_path = excel_dir / result_folder.replace('\\', '/')
                
                if not result_folder_path.exists():
                    print(f"[WARN] ResultFolder not found for {test_case_id}: {result_folder_path}")
                    continue
                
                print(f"[DEBUG] Processing {test_case_id} -> ResultFolder: {result_folder}")
                
                # Find all evidence files in this folder (non-recursive, direct children only)
                evidence_files = []
                for ext in evidence_patterns:
                    found_files = list(result_folder_path.glob(ext))  # No ** = non-recursive
                    evidence_files.extend(found_files)
                
                if evidence_files:
                    # Convert to relative paths from project root using PathNormalizer
                    test_evidence[test_case_id] = []
                    for evidence_path in evidence_files:
                        try:
                            if RESULTS_DIR.parent in evidence_path.parents:
                                relative_evidence_path = PathNormalizer.to_relative(evidence_path, RESULTS_DIR.parent)
                                if relative_evidence_path:
                                    test_evidence[test_case_id].append(relative_evidence_path)
                            else:
                                print(f"[WARN] Evidence path not within project root: {evidence_path}")
                        except Exception as e:
                            print(f"[ERROR] Could not process evidence path {evidence_path}: {e}")
                    
                    print(f"[DEBUG] Found {len(test_evidence[test_case_id])} evidence files for {test_case_id} in {result_folder}")
                else:
                    print(f"[DEBUG] No evidence files found for {test_case_id} in {result_folder_path}")
        else:
            print(f"[WARN] Required columns not found: ResultFolder={result_folder_col}, TestCaseNo={test_case_col}")
            print(f"[WARN] Available columns: {df.columns.tolist()}")
            print(f"[WARN] No evidence will be collected for this Excel file")
            test_evidence = {}
                
        print(f"[DEBUG] Final test_evidence: {test_evidence}")
        
        # Extract run timestamp from directory path
        run_timestamp = extract_timestamp_from_path(excel_path_obj)
        print(f"[DEBUG] Extracted timestamp: {run_timestamp}")
        
        # Feature name already extracted above
            
        return {
            "feature_name": feature_name,
            "excel_path": str(excel_path_obj.relative_to(RESULTS_DIR.parent)).replace("\\", "/"),
            "total": total,
            "passed": passed,
            "failed": failed,
            "failed_major": failed_major,
            "failed_blocker": failed_blocker,
            "pass_rate": round(pass_rate, 2),
            "status": status,
            "run_timestamp": run_timestamp,
            "test_evidence": test_evidence,
        }
    except Exception as e:
        print(f"Error parsing Excel data from {excel_path}: {e}")
        return None

# --- Routes ---
@app.route("/")
def index():
    return render_template("dashboard.html")

@app.route("/api/data")
def get_dashboard_data():
    try:
        all_excel_files = find_excel_files(RESULTS_DIR)
        
        # Group by run timestamp
        runs = {}
        for excel_file in all_excel_files:
            feature_data = parse_excel_data(excel_file)
            # Only include features that have been executed (total > 0)
            if feature_data and feature_data.get("total", 0) > 0:
                timestamp = feature_data["run_timestamp"]
                if timestamp not in runs:
                    runs[timestamp] = {
                        "timestamp": timestamp,
                        "features": []
                    }
                runs[timestamp]["features"].append(feature_data)
        
        # Sort runs by timestamp (most recent first)
        sorted_runs = sorted(runs.values(), key=lambda x: x["timestamp"], reverse=True)
        
        return jsonify({
            "runs": sorted_runs,
            "total_runs": len(sorted_runs)
        })
    except Exception as e:
        print(f"Error in get_dashboard_data: {e}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/excel_preview")
def excel_preview():
    """Preview Excel file content for debugging."""
    try:
        excel_path = request.args.get('path')
        if not excel_path:
            return jsonify({"error": "No path provided"}), 400
            
        # Allow both 'results/...' and absolute under RESULTS_DIR
        rel_norm = excel_path.lstrip('/\\')
        full_path = (RESULTS_DIR.parent / rel_norm)
        if not full_path.exists():
            return jsonify({"error": f"File not found: {excel_path}"}), 404
            
        df = pd.read_excel(full_path, sheet_name="MAIN")
        
        # Convert to JSON-serializable format with correct field names
        rows_data = df.fillna('').astype(str).to_dict('records')
        preview_data = {
            "headers": df.columns.tolist(),  # JavaScript expects 'headers'
            "rows": rows_data,               # JavaScript expects 'rows'
            "total_rows": len(df)
        }
        
        return jsonify(preview_data)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/export_pdf', methods=['POST'])
def export_pdf():
    """Export test results to PDF with enhanced formatting and optional screenshots."""
    if not REPORTLAB_AVAILABLE:
        return jsonify({'error': 'PDF download not available. ReportLab not installed.'}), 500
        
    try:
        options = request.get_json()
        if not options:
            return jsonify({'error': 'No options provided'}), 400
            
        scope = options.get('scope', 'latest')
        include_screenshots = options.get('include_screenshots', True)
        include_details = options.get('include_details', True)
        include_summary = options.get('include_summary', True)
        start_date = options.get('start_date')
        end_date = options.get('end_date')
        selected_features = options.get('features', [])

        # Gather all runs with unique feature identification
        all_excel_files = find_excel_files(RESULTS_DIR)
        runs = {}
        seen_features = set()  # Track unique features to prevent duplicates
        
        for excel_file in all_excel_files:
            feature_data = parse_excel_data(excel_file)
            if feature_data and feature_data["total"] > 0:  # Filter out NOT RUN features
                ts = feature_data["run_timestamp"]
                feature_key = f"{ts}_{feature_data['feature_name']}"
                
                # Skip if we've already seen this feature in this run
                if feature_key in seen_features:
                    continue
                    
                seen_features.add(feature_key)
                
                if ts not in runs:
                    runs[ts] = {"timestamp": ts, "features": []}
                runs[ts]["features"].append(feature_data)
                
        sorted_runs = sorted(runs.values(), key=lambda r: r["timestamp"], reverse=True)

        # Filter runs/features based on scope
        if scope == "latest":
            runs_to_export = [sorted_runs[0]] if sorted_runs else []
        elif scope == "features":
            runs_to_export = []
            for run in sorted_runs:
                filtered_features = [f for f in run["features"] if f["feature_name"] in selected_features]
                if filtered_features:
                    runs_to_export.append({"timestamp": run["timestamp"], "features": filtered_features})
        elif scope == "date_range":
            runs_to_export = [run for run in sorted_runs if (not start_date or run["timestamp"] >= start_date) and (not end_date or run["timestamp"] <= end_date)]
        else:
            runs_to_export = sorted_runs

        # Calculate overall metrics
        total_tests = sum(f['total'] for run in runs_to_export for f in run['features'])
        passed_tests = sum(f['passed'] for run in runs_to_export for f in run['features'])
        failed_tests = sum(f['failed'] for run in runs_to_export for f in run['features'])
        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        overall_status = "PASSED" if failed_tests == 0 else "FAILED"

        # Prepare PDF
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=50, bottomMargin=50)
        styles = getSampleStyleSheet()
        elements = []

        # Custom styles with banking brand theme - Updated font sizes for better readability
        title_style = styles['Title'].clone('BrandTitleStyle')
        title_style.fontSize = 20  # Increased from 18pt to 20pt for better readability
        title_style.spaceAfter = 25
        title_style.textColor = colors.HexColor("#8B4513")
        title_style.fontName = PDF_FONT_BOLD
        title_style.alignment = 1  # Center alignment
        
        # Banking professional heading style (Section headers)
        heading_style = styles['Heading1'].clone('BrandHeadingStyle')
        heading_style.fontSize = 16  # Increased from 14pt to 16pt for better readability
        heading_style.spaceAfter = 15
        heading_style.textColor = colors.HexColor("#8B4513")  # Deep brown-gold
        heading_style.fontName = PDF_FONT_BOLD
        heading_style.borderWidth = 1
        heading_style.borderColor = colors.HexColor("#D4AF37")
        heading_style.borderPadding = 8
        heading_style.backColor = colors.HexColor("#FFF8DC")
        
        # Subheading style with golden accent
        subheading_style = styles['Heading2'].clone('BrandSubheadingStyle')
        subheading_style.fontSize = 14  # Increased from 12pt to 14pt for better readability
        subheading_style.spaceAfter = 12
        subheading_style.textColor = colors.HexColor("#DAA520")  # Golden rod
        subheading_style.fontName = PDF_FONT_BOLD
        subheading_style.alignment = 1  # Center alignment
        subheading_style.borderWidth = 0
        subheading_style.borderColor = colors.HexColor("#D4AF37")
        subheading_style.borderPadding = 5
        
        # Custom feature name style (Subsection headers)
        feature_style = styles['Heading2'].clone('FeatureStyle')
        feature_style.fontSize = 14  # Increased from 12pt to 14pt for better readability
        feature_style.spaceAfter = 15
        feature_style.textColor = colors.HexColor("#B8860B")
        feature_style.fontName = PDF_FONT_BOLD
        feature_style.leftIndent = 5
        feature_style.borderWidth = 1
        feature_style.borderColor = colors.HexColor("#D4AF37")
        feature_style.borderPadding = 8
        feature_style.backColor = colors.HexColor("#FFFACD")
        
        # Professional normal text style (Test case descriptions, etc.)
        normal_style = styles['Normal'].clone('BrandNormalStyle')
        normal_style.fontSize = 12  # Increased from 10pt to 12pt for better readability
        normal_style.textColor = colors.HexColor("#2F4F4F")
        normal_style.fontName = PDF_FONT_NORMAL
        normal_style.leading = 12  # 1.2x line spacing (10pt * 1.2 = 12pt)
        
        # Create caption style for screenshot counts (9pt Regular as requested)
        caption_style = styles['Normal'].clone('CaptionStyle')
        caption_style.fontSize = 11  # Increased from 9pt to 11pt for better readability
        caption_style.textColor = colors.HexColor("#666666")
        caption_style.fontName = PDF_FONT_NORMAL
        caption_style.leading = 11  # 1.2x line spacing (9pt * 1.2 = 11pt)

        # === HEADER SECTION WITH BANKING BRAND ===
        # Create gradient-style title section
        title_table = Table([
            [Paragraph("TEST AUTOMATION REPORT", title_style)],
            [Paragraph("Krungsri Automation Project", subheading_style)]
        ], colWidths=[500])
        title_table.setStyle(TableStyle([
            ('BACKGROUND', (0,0), (-1,-1), colors.HexColor("#FFF8DC")),
            ('LINEBELOW', (0,0), (-1,-1), 3, colors.HexColor("#D4AF37")),
            ('LINEABOVE', (0,0), (-1,-1), 3, colors.HexColor("#B8860B")),
            ('ALIGN', (0,0), (-1,-1), 'CENTER'),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
            ('TOPPADDING', (0,0), (-1,-1), 20),
            ('BOTTOMPADDING', (0,0), (-1,-1), 20),
            ('LEFTPADDING', (0,0), (-1,-1), 40),
            ('RIGHTPADDING', (0,0), (-1,-1), 40),
        ]))
        elements.append(title_table)
        elements.append(Spacer(1, 25))
        
        # Professional report metadata with golden borders
        metadata_data = [
            ["Execution Time:", datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
            ["Total Features:", str(sum(len(run['features']) for run in runs_to_export))],
        ]
        
        metadata_table = Table(metadata_data, colWidths=[140, 220])
        metadata_table.setStyle(TableStyle([
            ('FONTNAME', (0,0), (-1,-1), PDF_FONT_BOLD),
            ('FONTSIZE', (0,0), (-1,-1), 9),  # Reduced to 9pt for metadata
            ('ALIGN', (0,0), (0,-1), 'RIGHT'),
            ('ALIGN', (1,0), (1,-1), 'LEFT'),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
            ('TEXTCOLOR', (0,0), (0,-1), colors.HexColor("#8B4513")),
            ('TEXTCOLOR', (1,0), (1,-1), colors.HexColor("#2F4F4F")),
            ('LINEBELOW', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
            ('BACKGROUND', (0,0), (-1,-1), colors.HexColor("#FFFEF7")),
            ('GRID', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
            ('TOPPADDING', (0,0), (-1,-1), 6),  # Improved padding
            ('BOTTOMPADDING', (0,0), (-1,-1), 6),
            ('LEFTPADDING', (0,0), (-1,-1), 8),
            ('RIGHTPADDING', (0,0), (-1,-1), 8),
            ('LEADING', (0,0), (-1,-1), 11),  # 1.2x line spacing (9pt * 1.2 = 11pt)
        ]))
        elements.append(metadata_table)
        elements.append(Spacer(1, 25))

        # === EXECUTIVE SUMMARY ===
        if include_summary:
            elements.append(Paragraph("EXECUTIVE SUMMARY", heading_style))
            elements.append(Spacer(1, 15))
            
            # Create horizontal summary table with proper borders and header separation
            summary_table_data = [
                # Header row
                ["Total Tests", "Passed", "Failed", "Pass Rate"],
                # Data row  
                [str(total_tests), str(passed_tests), str(failed_tests), f"{pass_rate:.2f}%"]
            ]
            
            # Create professional horizontal summary table with enhanced styling
            summary_table = Table(summary_table_data, colWidths=[105, 105, 105, 105])
            summary_table.setStyle(TableStyle([
                # Header styling - matches other tables
                ('BACKGROUND', (0,0), (-1,0), colors.HexColor("#8B4513")),
                ('TEXTCOLOR', (0,0), (-1,0), colors.white),
                ('FONTNAME', (0,0), (-1,0), PDF_FONT_BOLD),
                ('FONTSIZE', (0,0), (-1,0), 10),
                ('ALIGN', (0,0), (-1,0), 'CENTER'),
                
                # Data row styling with color coding
                ('FONTNAME', (0,1), (-1,1), PDF_FONT_BOLD),
                ('FONTSIZE', (0,1), (-1,1), 14),
                ('ALIGN', (0,1), (-1,1), 'CENTER'),
                ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                
                # Color coding for data values
                ('TEXTCOLOR', (0,1), (0,1), colors.HexColor("#2F4F4F")),   # Total Tests (dark gray)
                ('TEXTCOLOR', (1,1), (1,1), colors.HexColor("#228B22")),   # Passed (green)
                ('TEXTCOLOR', (2,1), (2,1), colors.HexColor("#CD5C5C")),   # Failed (red)
                ('TEXTCOLOR', (3,1), (3,1), colors.HexColor("#DAA520")),   # Pass Rate (gold)
                
                # Enhanced borders with Krungsri golden theme
                ('BOX', (0,0), (-1,-1), 2, colors.HexColor("#D4AF37")),
                ('INNERGRID', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
                ('LINEBELOW', (0,0), (-1,0), 2, colors.HexColor("#B8860B")),  # Clear header separator
                
                # Background colors for data row
                ('BACKGROUND', (0,1), (0,1), colors.HexColor("#F5F5F5")),   # Total Tests bg
                ('BACKGROUND', (1,1), (1,1), colors.HexColor("#E8F5E8")),   # Passed bg
                ('BACKGROUND', (2,1), (2,1), colors.HexColor("#FFEBEE")),   # Failed bg
                ('BACKGROUND', (3,1), (3,1), colors.HexColor("#FFF3E0")),   # Pass Rate bg
                
                # Enhanced padding for better appearance
                ('TOPPADDING', (0,0), (-1,0), 8),      # Header padding
                ('BOTTOMPADDING', (0,0), (-1,0), 8),   # Header padding
                ('TOPPADDING', (0,1), (-1,1), 12),     # Data row padding (larger for emphasis)
                ('BOTTOMPADDING', (0,1), (-1,1), 12),  # Data row padding
                ('LEFTPADDING', (0,0), (-1,-1), 8),
                ('RIGHTPADDING', (0,0), (-1,-1), 8),
            ]))
            elements.append(summary_table)
            elements.append(Spacer(1, 25))

            # Charts (only if matplotlib is available)
            if MATPLOTLIB_AVAILABLE:
                # Professional pie chart with banking color scheme
                if passed_tests > 0 or failed_tests > 0:
                    # Only include labels and values that are greater than 0
                    pie_labels = []
                    pie_sizes = []
                    pie_colors = []
                    
                    if passed_tests > 0:
                        pie_labels.append('Passed')
                        pie_sizes.append(passed_tests)
                        pie_colors.append('#228B22')  # Forest green
                    
                    if failed_tests > 0:
                        pie_labels.append('Failed')
                        pie_sizes.append(failed_tests)
                        pie_colors.append('#CD5C5C')  # Indian red
                    
                    # Create perfectly circular pie chart
                    fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(aspect="equal"))
                    pie_result = ax.pie(pie_sizes, labels=pie_labels, colors=pie_colors, 
                                        autopct='%1.2f%%', startangle=90, 
                                        textprops={'color':'#2F4F4F', 'fontweight':'bold', 'fontsize':10})
                    
                    # Add golden border to pie chart
                    wedges = pie_result[0]
                    for wedge in wedges:
                        wedge.set_edgecolor('#D4AF37')
                        wedge.set_linewidth(2)
                    
                    # Set title with simpler text
                    ax.set_title('TEST RESULT', fontsize=14, fontweight='bold', color='#8B4513', pad=20)
                    
                    # Ensure perfect circle
                    ax.axis('equal')
                    
                    pie_buf = io.BytesIO()
                    plt.savefig(pie_buf, format='png', bbox_inches='tight', transparent=True, dpi=200, 
                               facecolor='#FFFEF7', pad_inches=0.1)
                    plt.close(fig)  # Properly close the figure
                    pie_buf.seek(0)
                    
                    elements.append(ReportLabImage(pie_buf, width=70*mm, height=70*mm))
                    elements.append(Spacer(1, 15))



        # === FEATURE RESULTS SUMMARY ===
        elements.append(PageBreak())  # Start Feature Results on a new page
        elements.append(Paragraph("FEATURE TEST RESULTS", heading_style))
        elements.append(Spacer(1, 15))
        
        # Collect unique features to prevent duplicates
        unique_features = {}
        for run in runs_to_export:
            for feature in run['features']:
                # Ensure test_evidence present for this feature by re-parsing if needed
                try:
                    if not feature.get('test_evidence'):
                        print(f"[DEBUG] Re-parsing feature data for PDF: {feature['excel_path']}")
                        reparsed = parse_excel_data(PROJECT_ROOT / feature['excel_path'])
                        if reparsed and reparsed.get('test_evidence'):
                            feature['test_evidence'] = reparsed['test_evidence']
                            print(f"[DEBUG] Updated test_evidence for PDF: {list(feature['test_evidence'].keys())}")
                except Exception as e:
                    print(f"[DEBUG] Failed to re-parse for PDF: {e}")
                feature_key = f"{feature['feature_name']}_{run['timestamp']}"
                if feature_key not in unique_features:
                    unique_features[feature_key] = feature
        
        if unique_features:
            # Create table data with Paragraph objects for better text wrapping
            feature_table_data = [["Feature", "Status", "Total\nExecuted", "Passed", "Failed", "Pass\nRate"]]
            
            # Create cell styles for different column types
            feature_name_style = normal_style.clone('FeatureNameStyle')
            feature_name_style.fontSize = 11
            feature_name_style.fontName = PDF_FONT_BOLD
            feature_name_style.textColor = colors.HexColor("#8B4513")
            feature_name_style.alignment = 0  # Left align
            
            status_style = normal_style.clone('StatusStyle')
            status_style.fontSize = 11
            status_style.fontName = PDF_FONT_BOLD
            status_style.alignment = 1  # Center align
            
            number_style = normal_style.clone('NumberStyle')
            number_style.fontSize = 11
            number_style.alignment = 1  # Center align
            
            # Add data rows with simple string formatting (avoids Paragraph type issues)
            for feature in unique_features.values():
                # Status without icons - clean text only
                if feature['status'] == 'passed':
                    status_display = 'PASSED'
                elif feature['status'] == 'failed':
                    status_display = 'FAILED'
                else:
                    status_display = 'NOT RUN'
                
                feature_table_data.append([
                    feature["feature_name"],
                    status_display,
                    str(feature["total"]),
                    str(feature["passed"]),
                    str(feature["failed"]),
                    f'{feature["pass_rate"]:.2f}%'
                ])
            
            # Create professional table with flexible column widths
            feature_results_table = Table(feature_table_data, 
                                        colWidths=[100, 70, 70, 50, 50, 60], 
                                        repeatRows=1)
            
            # Create enhanced table style with better text handling
            feature_table_style = [
                # Header styling with golden theme
                ('BACKGROUND', (0,0), (-1,0), colors.HexColor("#8B4513")),
                ('TEXTCOLOR', (0,0), (-1,0), colors.white),
                # à¸ªà¹ˆà¸§à¸™à¸«à¸±à¸§à¸‚à¸­à¸‡à¸•à¸²à¸£à¸²à¸‡à¸„à¸§à¸£à¹ƒà¸Šà¹‰à¸Ÿà¸­à¸™à¸•à¹Œà¸•à¸±à¸§à¸«à¸™à¸²à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢
                ('FONTNAME', (0,0), (-1,0), PDF_FONT_BOLD),
                ('FONTSIZE', (0,0), (-1,0), 11),  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 9 à¹€à¸›à¹‡à¸™ 11 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                ('ALIGN', (0,0), (-1,0), 'CENTER'),
                
                # Data rows styling with proper alignment
                ('FONTNAME', (0,1), (-1,-1), PDF_FONT_NORMAL),
                ('FONTSIZE', (0,1), (-1,-1), 11),  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 9 à¹€à¸›à¹‡à¸™ 11 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                ('ALIGN', (0,1), (0,-1), 'LEFT'),    # Feature names left-aligned
                ('ALIGN', (1,1), (1,-1), 'CENTER'),  # Status centered
                ('ALIGN', (2,1), (-1,-1), 'CENTER'), # Numbers centered
                ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                
                # Feature column bold font for consistency
                ('FONTNAME', (0,1), (0,-1), PDF_FONT_BOLD),
                
                # Enhanced borders with Krungsri golden theme
                ('BOX', (0,0), (-1,-1), 2, colors.HexColor("#D4AF37")),
                ('INNERGRID', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
                ('LINEBELOW', (0,0), (-1,0), 2, colors.HexColor("#B8860B")),
                
                # Alternating row colors
                ('ROWBACKGROUNDS', (0,1), (-1,-1), [colors.HexColor("#FFFEF7"), colors.HexColor("#FFF8DC")]),
                
                # Text colors for specific columns
                ('TEXTCOLOR', (0,1), (0,-1), colors.HexColor("#8B4513")),  # Feature names
                ('TEXTCOLOR', (2,1), (2,-1), colors.HexColor("#2F4F4F")),  # Total tests
                ('TEXTCOLOR', (3,1), (3,-1), colors.HexColor("#228B22")),  # Passed (green)
                ('TEXTCOLOR', (4,1), (4,-1), colors.HexColor("#CD5C5C")),  # Failed (red)
                ('TEXTCOLOR', (5,1), (5,-1), colors.HexColor("#DAA520")),  # Pass rate
                
                # Enhanced padding for better readability
                ('TOPPADDING', (0,0), (-1,0), 6),      # Header padding reduced
                ('BOTTOMPADDING', (0,0), (-1,0), 6),   # Header padding reduced
                ('TOPPADDING', (0,1), (-1,-1), 8),     # Data rows padding
                ('BOTTOMPADDING', (0,1), (-1,-1), 8),  # Data rows padding
                ('LEFTPADDING', (0,0), (-1,-1), 8),
                ('RIGHTPADDING', (0,0), (-1,-1), 8),
            ]
            
            # Add status-specific colors for status column
            feature_list = list(unique_features.values())
            for row_idx, feature in enumerate(feature_list, start=1):
                if feature['status'] == 'passed':
                    status_color = colors.HexColor("#228B22")
                elif feature['status'] == 'failed':
                    status_color = colors.HexColor("#CD5C5C")
                else:
                    status_color = colors.HexColor("#666666")
                
                feature_table_style.append(('TEXTCOLOR', (1, row_idx), (1, row_idx), status_color))
            
            feature_results_table.setStyle(TableStyle(feature_table_style))
            elements.append(feature_results_table)
        else:
            elements.append(Paragraph("No feature test results available.", normal_style))
        
        elements.append(Spacer(1, 25))

        # === FAILED TEST CASES (Only if there are failures) ===
        failed_cases = []
        processed_features = set()  # Track processed features to prevent duplicates
        
        for run in runs_to_export:
            for feature in run['features']:
                feature_key = f"{feature['feature_name']}_{run['timestamp']}"
                if feature['failed'] > 0 and feature_key not in processed_features:
                    processed_features.add(feature_key)
                    excel_path = PROJECT_ROOT / feature['excel_path']
                    if excel_path.exists():
                        try:
                            df = pd.read_excel(excel_path)
                            
                            # Find relevant columns
                            status_col = next((c for c in df.columns if c.lower() in ['testresult', 'status', 'result']), None)
                            name_col = next((c for c in df.columns if c.lower() in ['testcasedescription', 'test case description', 'testcase', 'name', 'TestCaseDesc']), None)
                            if not name_col:
                                name_col = df.columns[0]
                            
                            error_col = next((c for c in df.columns if c.lower() in ['fail_description', 'testresult_description', 'result description', 'error', 'message', 'failure reason']), None)
                            
                            # Filter for executed tests only
                            df = filter_executed_rows(df)

                            # (Removed: not needed in failed cases section)
                            
                            # Find failed test cases
                            if status_col:
                                failed_df = df[df[status_col].str.lower() == 'fail']
                                for _, row in failed_df.iterrows():
                                    # Get error message and add proper spacing
                                    error_msg = str(row.get(error_col, "No error message")) if error_col else "No error message"
                                    
                                    failed_cases.append([
                                        str(feature['feature_name']),
                                        str(row.get(name_col, "")),
                                        str(error_msg)
                                    ])
                        except Exception as e:
                            print(f"Error processing failed cases for {feature['feature_name']}: {e}")

        if failed_cases:
            elements.append(Paragraph("FAILED TEST CASES DETAILS", heading_style))
            elements.append(Spacer(1, 15))
            
            # Create cell styles for failed cases table
            failed_feature_style = normal_style.clone('FailedFeatureStyle')
            failed_feature_style.fontSize = 8
            failed_feature_style.fontName = PDF_FONT_BOLD
            failed_feature_style.textColor = colors.HexColor("#8B4513")
            failed_feature_style.alignment = 0  # Left align
            
            failed_testcase_style = normal_style.clone('FailedTestCaseStyle')
            failed_testcase_style.fontSize = 8
            failed_testcase_style.textColor = colors.HexColor("#2F4F4F")
            failed_testcase_style.alignment = 0  # Left align
            
            failed_error_style = normal_style.clone('FailedErrorStyle')
            failed_error_style.fontSize = 8
            failed_error_style.textColor = colors.HexColor("#B71C1C")
            failed_error_style.alignment = 0  # Left align
            
            # Create table data with Paragraph objects for better text wrapping
            failed_table_data = [["Feature", "Test Case", "Fail Description"]]
            
            for case in failed_cases:
                # Truncate long text to prevent table overflow
                feature_name = str(case[0])[:20] + "..." if len(str(case[0])) > 20 else str(case[0])
                test_case_name = str(case[1])[:30] + "..." if len(str(case[1])) > 30 else str(case[1])
                error_msg = str(case[2])[:50] + "..." if len(str(case[2])) > 50 else str(case[2])
                
                # Create Paragraph objects with smaller font sizes
                feature_style = normal_style.clone('FeatureWrapStyle')
                feature_style.fontSize = 8
                feature_style.textColor = colors.HexColor("#8B4513")
                feature_style.fontName = PDF_FONT_BOLD
                feature_para = Paragraph(feature_name, feature_style)
                
                # Test case with smaller font
                test_case_style = normal_style.clone('TestCaseWrapStyle')
                test_case_style.fontSize = 8
                test_case_style.leading = 10  # Reduced line spacing
                test_case_style.textColor = colors.HexColor("#2F4F4F")
                test_case_para = Paragraph(test_case_name, test_case_style)
                
                # Fail description with smaller font
                fail_desc_style = normal_style.clone('FailDescWrapStyle') 
                fail_desc_style.fontSize = 8
                fail_desc_style.textColor = colors.HexColor("#B71C1C")
                fail_desc_style.leading = 10
                fail_desc_para = Paragraph(error_msg, fail_desc_style)
                
                failed_table_data.append([feature_para, test_case_para, fail_desc_para])
            
            # Create failed cases table with improved column widths and better size management
            # Use smaller column widths to prevent overflow
            failed_table = Table(failed_table_data, colWidths=[70, 150, 140], repeatRows=1)
            failed_table.setStyle(TableStyle([
                # Header styling
                ('BACKGROUND', (0,0), (-1,0), colors.HexColor("#8B4513")),
                ('TEXTCOLOR', (0,0), (-1,0), colors.white),
                # à¸ªà¹ˆà¸§à¸™à¸«à¸±à¸§à¸‚à¸­à¸‡à¸•à¸²à¸£à¸²à¸‡à¸„à¸§à¸£à¹ƒà¸Šà¹‰à¸Ÿà¸­à¸™à¸•à¹Œà¸•à¸±à¸§à¸«à¸™à¸²à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢
                ('FONTNAME', (0,0), (-1,0), PDF_FONT_BOLD),
                ('FONTSIZE', (0,0), (-1,0), 10),  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 8 à¹€à¸›à¹‡à¸™ 10 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                ('ALIGN', (0,0), (-1,0), 'CENTER'),
                
                # Data rows styling with smaller font size
                ('FONTNAME', (0,1), (-1,-1), PDF_FONT_NORMAL),
                ('FONTSIZE', (0,1), (-1,-1), 10),  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 8 à¹€à¸›à¹‡à¸™ 10 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                ('ALIGN', (0,1), (-1,-1), 'LEFT'),
                ('VALIGN', (0,0), (-1,-1), 'TOP'),
                
                # Professional borders and colors
                ('BOX', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),  # Reduced border width
                ('INNERGRID', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
                ('LINEBELOW', (0,0), (-1,0), 1, colors.HexColor("#B8860B")),  # Reduced border width
                
                # Alternating row colors
                ('ROWBACKGROUNDS', (0,1), (-1,-1), [colors.HexColor("#FFFEF7"), colors.HexColor("#FFF8DC")]),
                
                # Reduced padding to save space
                ('TOPPADDING', (0,0), (-1,0), 6),      # Header padding
                ('BOTTOMPADDING', (0,0), (-1,0), 6),   # Header padding
                ('TOPPADDING', (0,1), (-1,-1), 6),     # Data rows - reduced padding
                ('BOTTOMPADDING', (0,1), (-1,-1), 6),  # Data rows - reduced padding
                ('LEFTPADDING', (0,0), (-1,-1), 6),
                ('RIGHTPADDING', (0,0), (-1,-1), 6),
            ]))
            
            # Add table with page break handling
            try:
                elements.append(failed_table)
            except Exception as table_error:
                print(f"Table overflow error, trying to split: {table_error}")
                # If table is too large, try to split it into smaller chunks
                elements.append(Paragraph("FAILED TEST CASES (Table too large, showing summary only)", heading_style))
                for i, case in enumerate(failed_cases[:5]):  # Show only first 5 cases
                    elements.append(Paragraph(f"â€¢ {case[0]}: {case[1]}", normal_style))
                if len(failed_cases) > 5:
                    elements.append(Paragraph(f"... and {len(failed_cases) - 5} more failed cases", normal_style))
            elements.append(Spacer(1, 25))

        # === SCREENSHOTS SECTION (Optional) ===
        if include_screenshots:
            elements.append(PageBreak())  # Start screenshots on new page
            elements.append(Paragraph("TEST EVIDENCE SCREENSHOTS", heading_style))
            elements.append(Spacer(1, 15))
            
            for run in runs_to_export:
                for feature in run['features']:
                    elements.append(Paragraph(f"Feature: {feature['feature_name']}", feature_style))
                    elements.append(Spacer(1, 10))
                    
                    # Get Excel file path for this feature to extract test case descriptions and status
                    excel_path = PROJECT_ROOT / feature['excel_path']
                    df = None
                    if excel_path.exists():
                        try:
                            df = pd.read_excel(excel_path)
                            # Filter for executed tests only
                            df = filter_executed_rows(df)
                        except Exception as e:
                            df = None
                    
                    if df is not None and not df.empty:
                        # Get test case ID column
                        id_columns = ['Test Case ID', 'TestCaseID', 'Test Case', 'ID', 'TestCase', 'TestCaseNo', 'Name']
                        id_col = next((col for col in id_columns if col in df.columns), None)
                        status_columns = ['TestResult', 'Status', 'Result']
                        status_col = next((col for col in status_columns if col in df.columns), None)
                        
                        if id_col and status_col:
                            # Loop through Excel test cases instead of screenshot folders
                            for _, row in df.iterrows():
                                test_case = str(row[id_col]).strip()
                                test_case_status = str(row[status_col]).strip().upper()
                                
                                # Skip if test case is empty or status is not PASS/FAIL
                                if not test_case or test_case.lower() in ['nan', 'none', '']:
                                    continue
                                if test_case_status not in ['PASS', 'FAIL']:
                                    continue
                                
                                # Find matching screenshot folder for this Excel test case
                                images = []
                                actual_folder_name = test_case
                                
                                if feature.get('test_evidence'):
                                    # Try exact match first
                                    if test_case in feature['test_evidence']:
                                        images = feature['test_evidence'][test_case]
                                        actual_folder_name = test_case
                                    else:
                                        # Try fuzzy matching: find folders that start with test_case + "_"
                                        # e.g., "TC001" matches folder "TC001_52224444444"
                                        for folder_name, folder_images in feature['test_evidence'].items():
                                            if folder_name.startswith(test_case + '_') or folder_name == test_case:
                                                images = folder_images
                                                actual_folder_name = folder_name
                                                break
                                
                                # Create test case header with status
                                status_str = f" <font color='#28a745'>[PASS]</font>" if test_case_status == "PASS" else \
                                             f" <font color='#dc3545'>[FAIL]</font>" if test_case_status == "FAIL" else ""
                                
                                test_case_style = styles['Heading4'].clone('TestCaseStyle')
                                test_case_style.fontSize = 12
                                test_case_style.spaceAfter = 10
                                test_case_style.textColor = colors.HexColor("#B8860B")
                                test_case_style.fontName = PDF_FONT_BOLD
                                test_case_style.leftIndent = 5
                                test_case_style.borderWidth = 1
                                test_case_style.borderColor = colors.HexColor("#D4AF37")
                                test_case_style.borderPadding = 6
                                test_case_style.backColor = colors.HexColor("#FFFEF7")
                                
                                elements.append(Paragraph(f"Test Case: {actual_folder_name}{status_str}", test_case_style))
                                
                                # Get and display test case description from Excel file
                                test_case_description = get_test_case_description(excel_path, test_case)
                                if test_case_description:
                                    elements.append(Paragraph(f"<b>Description:</b> {test_case_description}", normal_style))
                                    elements.append(Spacer(1, 8))
                                else:
                                    elements.append(Paragraph("<b>Description:</b> No description available", normal_style))
                                    elements.append(Spacer(1, 8))
                                
                                # Add failure reason for failed test cases
                                if test_case_status == "FAIL":
                                    try:
                                        # Find error column
                                        error_col = None
                                        for col in df.columns:
                                            if col.lower() in ['fail_description', 'testresult_description', 'result description', 'error', 'message', 'failure reason']:
                                                error_col = col
                                                break
                                        
                                        if error_col:
                                            error_msg = str(row[error_col]).strip()
                                            if error_msg and error_msg.lower() not in ['nan', 'none', '']:
                                                # Create custom style for error message
                                                error_style = styles['Normal'].clone('ErrorStyle')
                                                error_style.fontSize = 10
                                                error_style.textColor = colors.HexColor("#dc3545")
                                                error_style.fontName = PDF_FONT_BOLD
                                                error_style.leftIndent = 12
                                                error_style.rightIndent = 12
                                                error_style.spaceBefore = 8
                                                error_style.spaceAfter = 8
                                                error_style.backColor = colors.HexColor("#FFEBEE")
                                                error_style.borderColor = colors.HexColor("#dc3545")
                                                error_style.borderWidth = 1
                                                error_style.borderPadding = 8
                                                error_style.borderRadius = 4
                                                
                                                elements.append(Paragraph(f"<b><font color='#B71C1C'>âŒ Failure Reason:</font></b><br/><font color='#D32F2F'>{error_msg}</font>", error_style))
                                                elements.append(Spacer(1, 8))
                                    except Exception as e:
                                        print(f"Error getting failure reason for {actual_folder_name}: {e}")
                                
                                                                # Handle screenshots and HTML files
                                if images:
                                    # Show all screenshots, not just PDF ones
                                    all_images = images
                                    
                                    elements.append(Paragraph(f"Total Evidence Files: {len(all_images)}", caption_style))
                                    elements.append(Spacer(1, 8))
                                    
                                    # --- High-quality image grid with original resolution and captions ---
                                    if all_images:
                                        # Process images one by one to maintain original resolution
                                        for img_path in all_images:
                                            img_abs = PROJECT_ROOT / img_path
                                            if img_abs.exists():
                                                try:
                                                    # Get filename for caption
                                                    img_filename = img_path.split('/')[-1]
                                                    file_extension = img_path.lower().split('.')[-1] if '.' in img_path else ''
                                    
                                                    # Check if this is an HTML file
                                                    if file_extension in ['html', 'htm']:
                                                        # ðŸ”§ FIX: Use existing thumbnail instead of creating new one
                                                        print(f"[DEBUG] Looking for existing thumbnail: {img_path}")
                                                        try:
                                                            thumbnail_path = _get_thumbnail_path(img_abs)
                                                            if thumbnail_path.exists():
                                                                print(f"[DEBUG] Using existing thumbnail: {thumbnail_path}")
                                                                reportlab_img = ReportLabImage(str(thumbnail_path), width=500, height=400)
                                                            else:
                                                                print(f"[DEBUG] No thumbnail found, skipping HTML conversion")
                                                                reportlab_img = None
                                                        except:
                                                            reportlab_img = None
                                                        
                                                        if reportlab_img:
                                                            pdf_width = reportlab_img.imageWidth
                                                            pdf_height = reportlab_img.imageHeight
                                                            print(f"[DEBUG] Using existing thumbnail. Dimensions: {pdf_width}x{pdf_height}")
                                                        else:
                                                            # Fallback: create simple placeholder for HTML
                                                            print(f"[DEBUG] No thumbnail available, creating simple placeholder")
                                                            if PIL_AVAILABLE:
                                                                placeholder_img = PILImage.new("RGB", (500, 400), color=(245, 247, 250))
                                                                draw = ImageDraw.Draw(placeholder_img)
                                                                try:
                                                                    font = ImageFont.load_default()
                                                                except Exception:
                                                                    font = None
                                                                
                                                                # Draw placeholder text
                                                                draw.text((20, 180), "HTML File", fill=(64, 64, 64), font=font)
                                                                draw.text((20, 200), img_filename[:50], fill=(96, 96, 96), font=font)
                                                                draw.text((20, 220), "(Thumbnail not available)", fill=(128, 128, 128), font=font)
                                                                
                                                                with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img:
                                                                    placeholder_img.save(temp_img.name, format='JPEG', quality=75)
                                                                    reportlab_img = ReportLabImage(temp_img.name, width=500, height=400)
                                                                    pdf_width, pdf_height = 500, 400
                                                                    
                                                                    # Clean up temp file
                                                                    try:
                                                                        os.unlink(temp_img.name)
                                                                    except:
                                                                        pass
                                                            else:
                                                                # If PIL not available, create text placeholder
                                                                elements.append(Paragraph(f"<b>HTML File:</b> {img_filename}", normal_style))
                                                                elements.append(Paragraph("(HTML preview not available)", caption_style))
                                                                elements.append(Spacer(1, 10))
                                                                continue
                                                    else:
                                                        # Regular image file processing
                                                        # Use PIL Image to process, ReportLab Image for PDF
                                                        if PIL_AVAILABLE:
                                                            with PILImage.open(str(img_abs)) as pil_img:
                                                                # Get original dimensions
                                                                original_width, original_height = pil_img.size
                                                                
                                                                # Calculate maximum dimensions for PDF (maintain aspect ratio)
                                                                max_width_pdf = 500  # Maximum width in points
                                                                max_height_pdf = 400  # Maximum height in points
                                                                
                                                                # Calculate scaling factor to maintain aspect ratio
                                                                width_ratio = max_width_pdf / original_width
                                                                height_ratio = max_height_pdf / original_height
                                                                scale_ratio = min(width_ratio, height_ratio)
                                                                
                                                                # Calculate final dimensions for PDF
                                                                pdf_width = original_width * scale_ratio
                                                                pdf_height = original_height * scale_ratio
                                                                
                                                                # Convert to RGB if necessary and save with high quality
                                                                if pil_img.mode in ('RGBA', 'LA', 'P'):
                                                                    rgb_img = PILImage.new('RGB', pil_img.size, (255, 255, 255))
                                                                    if pil_img.mode == 'P':
                                                                        pil_img = pil_img.convert('RGBA')
                                                                    rgb_img.paste(pil_img, mask=pil_img.split()[-1] if pil_img.mode in ('RGBA', 'LA') else None)
                                                                    pil_img = rgb_img
                                                                
                                                                with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img:
                                                                    pil_img.save(temp_img.name, format='JPEG', quality=75, optimize=True, dpi=(150, 150))
                                                                    # Use original resolution with calculated PDF dimensions
                                                                    reportlab_img = ReportLabImage(temp_img.name, width=pdf_width, height=pdf_height)
                                                                    
                                                                    # Clean up temp file
                                                                    try:
                                                                        os.unlink(temp_img.name)
                                                                    except:
                                                                        pass
                                                        else:
                                                            # Fallback: use original image with moderate dimensions
                                                            reportlab_img = ReportLabImage(str(img_abs), width=400, height=300)
                                                            pdf_width, pdf_height = 400, 300
                                                    
                                                    # Create image with caption
                                                    file_type_label = "HTML File" if file_extension in ['html', 'htm'] else "Screenshot"
                                                    img_with_caption = [
                                                        [reportlab_img],
                                                        [Paragraph(f"<b>{file_type_label}:</b> {img_filename}", caption_style)]
                                                    ]
                                                    
                                                    # Create table for image and caption
                                                    img_table = Table(img_with_caption, colWidths=[pdf_width])
                                                    img_table.setStyle(TableStyle([
                                                        ('ALIGN', (0,0), (-1,-1), 'CENTER'),
                                                        ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                                                        ('LEFTPADDING', (0,0), (-1,-1), 0),
                                                        ('RIGHTPADDING', (0,0), (-1,-1), 0),
                                                        ('TOPPADDING', (0,0), (-1,0), 10),  # Image padding
                                                        ('BOTTOMPADDING', (0,0), (-1,0), 5),  # Image padding
                                                        ('TOPPADDING', (0,1), (-1,1), 5),   # Caption padding
                                                        ('BOTTOMPADDING', (0,1), (-1,1), 15), # Caption padding
                                                    ]))
                                                    
                                                    elements.append(img_table)
                                                    elements.append(Spacer(1, 10))
                                                    
                                                except Exception as e:
                                                    print(f"Error processing file {img_path}: {e}")
                                                    elements.append(Paragraph(f"Error loading file: {img_path}", normal_style))
                                                    elements.append(Spacer(1, 10))
                                            else:
                                                elements.append(Paragraph(f"File not found: {img_path}", normal_style))
                                                elements.append(Spacer(1, 10))
                                    else:
                                        elements.append(Paragraph("No evidence files available for this test case.", caption_style))
                                else:
                                    # No matching evidence folder found - show "No evidence found"
                                    elements.append(Paragraph("Evidence Files: No evidence found", caption_style))
                                
                                elements.append(Spacer(1, 20))
                    else:
                        elements.append(Paragraph("No test case data available from Excel file.", normal_style))
                    
                    # Add page break between features for better organization
                    elements.append(PageBreak())

        # === FOOTER ===
        # Create footer style (8pt Regular as requested)
        footer_style = styles['Normal'].clone('FooterStyle')
        footer_style.fontSize = 10  # Increased from 8pt to 10pt for better readability
        footer_style.textColor = colors.HexColor("#666666")
        footer_style.fontName = PDF_FONT_NORMAL  # Use Thai font
        footer_style.leading = 10  # 1.25x line spacing (8pt * 1.25 = 10pt)
        footer_style.alignment = 1  # Center alignment
        
        elements.append(Spacer(1, 30))
        elements.append(Paragraph("_______________________________________________", footer_style))
        elements.append(Spacer(1, 10))
        elements.append(Paragraph("Generated by: Test Automation Dashboard v1.0", footer_style))
        elements.append(Paragraph(f"Report Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", footer_style))
        elements.append(Paragraph("Confidential - For Internal Use Only", footer_style))

        # Build PDF
        doc.build(elements)
        buffer.seek(0)
        
        # Generate filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"DRDB_TestReport_{timestamp}.pdf"
        
        return send_file(buffer, as_attachment=True, download_name=filename, mimetype='application/pdf')
        
    except Exception as e:
        print(f"PDF Export Error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

def generate_test_case_pdf_core(test_case_id, feature_name, run_timestamp, feature_data, test_case_row, mode='full'):
    """Core PDF generation logic - reusable for both individual and ZIP downloads.
    Robust to both pandas.Series and dict rows.
    
    Args:
        test_case_id: Test case identifier
        feature_name: Feature name
        run_timestamp: Execution timestamp
        feature_data: Feature data dictionary
        test_case_row: Row data (pandas Series or dict)
        mode: 'full' for complete PDF, 'optimized' for reduced content
    """
    try:
        # Use ExcelRowAccessor utility for row access
        accessor = ExcelRowAccessor(test_case_row)
        
        # Get test case information using COLUMN_NAMES constants
        test_case_description = accessor.get_by_candidates(COLUMN_NAMES['description'], '')
        status_raw = accessor.get_by_candidates(COLUMN_NAMES['status'], 'UNKNOWN')
        error_message = accessor.get_by_candidates(COLUMN_NAMES['error'], '')
        expected_result = accessor.get_by_candidates(COLUMN_NAMES['expected'], '')
        
        try:
            print(f"[DEBUG][Row Values] test_case_id={test_case_id} mode={mode}")
            print(f"[DEBUG][Row Values] desc='{test_case_description[:100] if test_case_description else None}...' status='{status_raw}'")
        except Exception:
            pass
        
        # Get screenshots for this test case and find folder name
        screenshots = []
        folder_name_for_title = None
        
        if feature_data.get('test_evidence'):
            # First priority: Look for exact match
            if test_case_id in feature_data['test_evidence']:
                screenshots = feature_data['test_evidence'][test_case_id]
                folder_name_for_title = test_case_id
            else:
                # Second priority: Look for fuzzy match
                for folder_name, folder_images in feature_data['test_evidence'].items():
                    if folder_name.startswith(test_case_id + '_') or folder_name == test_case_id:
                        screenshots = folder_images
                        folder_name_for_title = folder_name
                        break
        
        # Limit screenshots in optimized mode
        if mode == 'optimized' and screenshots:
            screenshots = screenshots[:5]  # Limit to 5 files in optimized mode
            print(f"[DEBUG] Optimized mode: limited evidence files to {len(screenshots)}")
        
        # Extract test case information with correct separation
        # 1. Title: Use folder name from screenshot folder (as requested)
        # 2. Test Case Description: Use Excel data (separate field)
        
        # Get title from folder name (for header)
        if folder_name_for_title and folder_name_for_title != test_case_id:
            if folder_name_for_title.startswith(test_case_id + '_'):
                title_name = folder_name_for_title[len(test_case_id + '_'):]  # Use "225522422" for title
            else:
                title_name = folder_name_for_title
        else:
            title_name = test_case_id  # fallback to ID if no folder
        
        # Process test case description
        if not test_case_description or str(test_case_description).lower() in ['nan', 'none', '']:
            test_case_description = test_case_id  # fallback to ID if no description
        
        # Use title_name for header
        test_case_name = title_name
        
        # Process status
        test_case_status = str(status_raw).strip().upper() if status_raw is not None else 'UNKNOWN'
        error_message = str(error_message) if error_message is not None else ''
        expected_result = str(expected_result) if expected_result is not None else ''
        
        # Apply optimizations if in optimized mode
        if mode == 'optimized':
            # Truncate long descriptions
            if test_case_description and len(str(test_case_description)) > 500:
                test_case_description = str(test_case_description)[:500] + '...'
            if error_message and len(error_message) > 1000:
                error_message = error_message[:1000] + '...'

        try:
            print(f"[DEBUG][Row Values] name='{test_case_name}' status='{test_case_status}' has_error={bool(error_message)} has_expected={bool(expected_result)}")
        except Exception:
            pass

        # Generate PDF
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=30, bottomMargin=30)
        styles = getSampleStyleSheet()
        elements = []

        # Custom styles
        title_style = styles['Title'].clone('TestCaseTitleStyle')
        title_style.fontSize = 18
        title_style.spaceAfter = 20
        title_style.textColor = colors.HexColor("#8B4513")
        title_style.fontName = PDF_FONT_BOLD
        title_style.alignment = 1
        
        header_style = styles['Heading1'].clone('TestCaseHeaderStyle')
        header_style.fontSize = 16
        header_style.spaceAfter = 15
        header_style.textColor = colors.HexColor("#8B4513")
        header_style.fontName = PDF_FONT_BOLD
        
        normal_style = styles['Normal'].clone('TestCaseNormalStyle')
        normal_style.fontSize = 12
        normal_style.textColor = colors.HexColor("#2F4F4F")
        normal_style.fontName = PDF_FONT_NORMAL
        normal_style.leading = 12

        caption_style = styles['Normal'].clone('TestCaseCaptionStyle')
        caption_style.fontSize = 11
        caption_style.textColor = colors.HexColor("#666666")
        caption_style.fontName = PDF_FONT_NORMAL
        caption_style.leading = 11
        caption_style.alignment = 1

        # Header - Use folder name as priority  
        safe_title = escape_html_for_pdf(f"{test_case_id}: {test_case_name}")
        elements.append(Paragraph(safe_title, title_style))
        
        # Status
        if test_case_status == "PASS":
            status_color = colors.HexColor("#28a745")
            status_bg_color = colors.HexColor("#d4edda")
        elif test_case_status == "FAIL (MAJOR)":
            status_color = colors.HexColor("#ff5722")
            status_bg_color = colors.HexColor("#f8d7da")
        elif test_case_status == "FAIL (BLOCK)":
            status_color = colors.HexColor("#dc3545")
            status_bg_color = colors.HexColor("#f8d7da")
        else:
            status_color = colors.HexColor("#6c757d")
            status_bg_color = colors.HexColor("#e2e3e5")
            
        status_style = styles['Normal'].clone('StatusStyle')
        status_style.fontSize = 14  # à¸¥à¸”à¸‚à¸™à¸²à¸”à¸¥à¸‡à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸žà¸­à¸”à¸µ
        status_style.fontName = PDF_FONT_BOLD
        status_style.textColor = status_color
        status_style.alignment = 1
        status_style.borderWidth = 2
        status_style.borderColor = status_color
        status_style.borderPadding = 12  # à¸¥à¸” padding à¸¥à¸‡à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢
        status_style.backColor = status_bg_color
        
        # Make status badge take the full content width so we can match the metadata table width
        content_width = A4[0] - doc.leftMargin - doc.rightMargin
        status_table = Table(
            [[Paragraph(f"Test Result: {test_case_status}", status_style)]],
            colWidths=[content_width]
        )
        status_table.setStyle(TableStyle([
            ('ALIGN', (0,0), (-1,-1), 'CENTER'),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE')
        ]))
        elements.append(status_table)
        elements.append(Spacer(1, 20))
        
        # Metadata
        metadata_data = [
            ["Execution Date & Time:", format_timestamp_professional(run_timestamp)],
            ["Feature Category:", feature_name],
            ["Test Case ID:", test_case_id],
        ]
        
        if test_case_description and test_case_description != test_case_id:
            metadata_data.append(["Test Case Description:", test_case_description])
        
        if expected_result and expected_result.strip() and expected_result.lower() not in ['nan', 'none', '']:
            metadata_data.append(["Expected Result:", expected_result])

        # Move Fail_Description outside the table to prevent a single very-tall row
        fail_desc_text = None
        if error_message and error_message.strip() and error_message.lower() not in ['nan', 'none', '']:
            fail_desc_text = error_message
        
        # Build metadata rows with Paragraphs and CJK word wrapping to avoid overflow with long text
        label_style = styles['Normal'].clone('MetaLabelStyle')
        label_style.fontSize = 11  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 9 à¹€à¸›à¹‡à¸™ 11 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
        label_style.textColor = colors.HexColor("#8B4513")
        label_style.fontName = PDF_FONT_BOLD
        label_style.leading = 13  # à¹€à¸žà¸´à¹ˆà¸¡ leading à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸‚à¸™à¸²à¸”à¸Ÿà¸­à¸™à¸•à¹Œ
        label_style.wordWrap = 'CJK'

        value_style = styles['Normal'].clone('MetaValueStyle')
        value_style.fontSize = 11  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 9 à¹€à¸›à¹‡à¸™ 11 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
        value_style.textColor = colors.HexColor("#2F4F4F")
        value_style.fontName = PDF_FONT_NORMAL
        value_style.leading = 13  # à¹€à¸žà¸´à¹ˆà¸¡ leading à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸‚à¸™à¸²à¸”à¸Ÿà¸­à¸™à¸•à¹Œ
        value_style.wordWrap = 'CJK'

        metadata_rows = []
        for label, value in metadata_data:
            try:
                # Safely process both label and value text
                safe_label = escape_html_for_pdf(str(label))
                safe_value = escape_html_for_pdf(str(value))
                metadata_rows.append([
                    Paragraph(safe_label, label_style),
                    Paragraph(safe_value, value_style)
                ])
            except Exception as e:
                print(f"[ERROR] Failed to add metadata row '{label}': {e}")
                # Fallback to plain text
                metadata_rows.append([
                    Paragraph(str(label), label_style),
                    Paragraph(str(value).replace('<', '&lt;').replace('>', '&gt;').replace('&', '&amp;'), value_style)
                ])

        # Make table span the full content width (same as status badge)
        label_col_width = 160
        if content_width - label_col_width < 160:
            label_col_width = max(120, content_width * 0.33)
        value_col_width = content_width - label_col_width

        metadata_table = Table(metadata_rows, colWidths=[label_col_width, value_col_width])
        metadata_table.setStyle(TableStyle([
            ('FONTNAME', (0,0), (0,-1), PDF_FONT_BOLD),
            ('FONTNAME', (1,0), (1,-1), PDF_FONT_NORMAL),
            ('FONTSIZE', (0,0), (-1,-1), 9),
            ('ALIGN', (0,0), (0,-1), 'RIGHT'),
            ('ALIGN', (1,0), (1,-1), 'LEFT'),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
            ('TEXTCOLOR', (0,0), (0,-1), colors.HexColor("#8B4513")),
            ('TEXTCOLOR', (1,0), (1,-1), colors.HexColor("#2F4F4F")),
            ('LINEBELOW', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
            ('BACKGROUND', (0,0), (-1,-1), colors.HexColor("#FFFEF7")),
            ('GRID', (0,0), (-1,-1), 1, colors.HexColor("#D4AF37")),
            ('TOPPADDING', (0,0), (-1,-1), 6),
            ('BOTTOMPADDING', (0,0), (-1,-1), 6),
            ('LEFTPADDING', (0,0), (-1,-1), 8),
            ('RIGHTPADDING', (0,0), (-1,-1), 8),
        ]))
        elements.append(metadata_table)
        elements.append(Spacer(1, 25))

        # Render long Fail_Description as a standalone paragraph block (can break across pages)
        if fail_desc_text is not None:
            try:
                error_style = styles['Normal'].clone('ErrorBlockStyle')
                error_style.fontSize = 11  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 10 à¹€à¸›à¹‡à¸™ 11 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                error_style.textColor = colors.HexColor("#dc3545")
                # à¹ƒà¸Šà¹‰à¸Ÿà¸­à¸™à¸•à¹Œà¸•à¸±à¸§à¸«à¸™à¸²à¸—à¸µà¹ˆà¸£à¸­à¸‡à¸£à¸±à¸šà¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹à¸—à¸™à¸à¸²à¸£à¸®à¸²à¸£à¹Œà¸”à¹‚à¸„à¹‰à¸” Helvetica
                error_style.fontName = PDF_FONT_BOLD
                error_style.leftIndent = 6
                error_style.rightIndent = 6
                error_style.spaceBefore = 6
                error_style.spaceAfter = 12
                error_style.backColor = colors.HexColor("#FFEBEE")
                error_style.borderColor = colors.HexColor("#dc3545")
                error_style.borderWidth = 1
                error_style.borderPadding = 8
                error_style.borderRadius = 4
                error_style.leading = 14  # à¹€à¸žà¸´à¹ˆà¸¡ leading à¸ˆà¸²à¸ 12 à¹€à¸›à¹‡à¸™ 14 à¹€à¸žà¸·à¹ˆà¸­à¹€à¸§à¹‰à¸™à¸šà¸£à¸£à¸—à¸±à¸”à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡
                error_style.wordWrap = 'CJK'

                # Safely escape the text to prevent XML/HTML parsing errors
                print(f"[DEBUG] Processing Fail_Description for PDF (length: {len(fail_desc_text)} chars)")
                safe_fail_text = escape_html_for_pdf(fail_desc_text)
                print(f"[DEBUG] Escaped text length: {len(safe_fail_text)}")
                
                elements.append(Paragraph(f"<b>Fail_Description:</b><br/>{safe_fail_text}", error_style))
                elements.append(Spacer(1, 10))
                print(f"[DEBUG] Successfully added Fail_Description to PDF")
            except Exception as e:
                print(f"[ERROR] Failed to add Fail_Description to PDF: {e}")
                import traceback
                traceback.print_exc()
                
                # Fallback: Add as plain text without formatting
                try:
                    print(f"[DEBUG] Trying fallback method for Fail_Description")
                    fallback_style = styles['Normal'].clone('FallbackErrorStyle')
                    fallback_style.fontSize = 11  # à¹€à¸žà¸´à¹ˆà¸¡à¸ˆà¸²à¸ 9 à¹€à¸›à¹‡à¸™ 11 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢à¸‚à¸¶à¹‰à¸™
                    fallback_style.textColor = colors.HexColor("#dc3545")
                    fallback_style.fontName = PDF_FONT_NORMAL
                    fallback_style.leading = 13  # à¹€à¸žà¸´à¹ˆà¸¡ leading à¹ƒà¸«à¹‰à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸‚à¸™à¸²à¸”à¸Ÿà¸­à¸™à¸•à¹Œ
                    fallback_style.wordWrap = 'CJK'
                    
                    # Remove any potentially problematic characters and truncate if extremely long
                    clean_text = re.sub(r'[<>&"\']', ' ', str(fail_desc_text))
                    if len(clean_text) > 5000:
                        clean_text = clean_text[:5000] + "... [à¸•à¸±à¸”à¸—à¸­à¸™à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸¡à¸²à¸]"
                    
                    elements.append(Paragraph(f"Fail_Description: {clean_text}", fallback_style))
                    elements.append(Spacer(1, 10))
                    print(f"[DEBUG] Fallback method succeeded")
                except Exception as e2:
                    print(f"[ERROR] Fallback Fail_Description also failed: {e2}")
                    import traceback
                    traceback.print_exc()
                    
                    # Last resort: Add a simple note
                    try:
                        simple_msg = f"Fail_Description: [à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹„à¸”à¹‰à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¡à¸µà¸„à¸§à¸²à¸¡à¸¢à¸²à¸§ {len(str(fail_desc_text))} à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£]"
                        elements.append(Paragraph(simple_msg, styles['Normal']))
                        elements.append(Spacer(1, 10))
                        print(f"[DEBUG] Added simplified error message")
                    except Exception as e3:
                        print(f"[ERROR] Even simple error message failed: {e3}")
                        # Skip this section entirely if all methods fail

        # Screenshots and HTML files (include all evidence, no limit)
        if screenshots:
            elements.append(PageBreak())  # Start evidence on new page
            elements.append(Paragraph("Test Evidence Files", header_style))
            elements.append(Spacer(1, 15))
            
            # Show all evidence files, not just screenshots, but limit to prevent huge files
            all_evidence = screenshots

            # Sorting Screenshot in PDF
            def extract_number(file_path):
                """Extract leading number from filename for sorting"""
                filename = file_path.split('/')[-1] if file_path else ''
                match = re.match(r'^(\d+)', filename)
                return int(match.group(1)) if match else 0
            
            # Sort by leading number in filename
            all_evidence = sorted(all_evidence, key=extract_number)
            
            # Limit evidence files to prevent huge PDF files (max 100 files)
            if len(all_evidence) > 100:
                print(f"[WARNING] Too many evidence files ({len(all_evidence)}), limiting to 100")
                all_evidence = all_evidence[:100]
                
            if all_evidence:
                evidence_count_msg = f"Evidence Files: {len(all_evidence)}"
                if len(screenshots) > 100:
                   evidence_count_msg += f" (limited from {len(screenshots)} total)"
                elements.append(Paragraph(evidence_count_msg, caption_style))
                elements.append(Spacer(1, 15))
                
                # Sort evidence files by file modification time for execution sequence
                # sorted_evidence = sorted(all_evidence, key=lambda file_path: (PROJECT_ROOT / file_path).stat().st_mtime if (PROJECT_ROOT / file_path).exists() else 0)
                
                for idx, file_path in enumerate(all_evidence, 1):
                    file_abs = RESULTS_DIR.parent / file_path
                    print(f"[DEBUG] ton file_abs: {file_abs}")
                    # Get filename (defined outside try block for error handling)
                    filename = file_path.split('/')[-1] if file_path else f"file_{idx}"
                    file_extension = file_path.lower().split('.')[-1] if '.' in file_path else ''
                    
                    if file_extension == 'xls'or file_extension == 'xlsx': continue
                    if file_abs.exists():
                        try:
                            # Check if this is an HTML file
                            if file_extension in ['html', 'htm']:
                                # ðŸ”§ FIX: Use existing thumbnail instead of creating new one
                                print(f"[DEBUG] Looking for existing thumbnail for PDF: {file_path}")
                                try:
                                    thumbnail_path = _get_thumbnail_path(file_abs)
                                    if thumbnail_path.exists():
                                        print(f"[DEBUG] Using existing thumbnail for PDF: {thumbnail_path}")
                                        reportlab_img = ReportLabImage(str(thumbnail_path), width=400, height=300)
                                        pdf_width = 400
                                        pdf_height = 300
                                    else:
                                        print(f"[DEBUG] No thumbnail found for PDF, creating placeholder")
                                        reportlab_img = None
                                except:
                                    reportlab_img = None
                                
                                if reportlab_img:
                                    print(f"[DEBUG] Using existing thumbnail for PDF. Dimensions: {pdf_width}x{pdf_height}")
                                else:
                                    # Fallback: create placeholder for HTML
                                    print(f"[DEBUG] No thumbnail available for PDF, creating placeholder")
                                    if PIL_AVAILABLE:
                                        placeholder_img = PILImage.new("RGB", (400, 300), color=(245, 247, 250))
                                        draw = ImageDraw.Draw(placeholder_img)
                                        try:
                                            font = ImageFont.load_default()
                                        except Exception:
                                            font = None
                                        
                                        # Draw placeholder text
                                        draw.text((20, 150), "HTML Preview", fill=(64, 64, 64), font=font)
                                        draw.text((20, 180), filename[:40], fill=(96, 96, 96), font=font)
                                        
                                        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img:
                                            placeholder_img.save(temp_img.name, format='JPEG', quality=75)
                                            reportlab_img = ReportLabImage(temp_img.name, width=400, height=300)
                                            pdf_width, pdf_height = 400, 300
                                            
                                            # Clean up temp file
                                            try:
                                                os.unlink(temp_img.name)
                                            except:
                                                pass
                                    else:
                                        # If PIL not available, create text placeholder
                                        elements.append(Paragraph(f"<b>HTML File:</b> {filename}", normal_style))
                                        # Use caption_style if defined above, otherwise fallback to normal_style
                                        try:
                                            elements.append(Paragraph("(HTML preview not available)", caption_style))
                                        except Exception:
                                            elements.append(Paragraph("(HTML preview not available)", normal_style))
                                        elements.append(Spacer(1, 10))
                                        continue
                            else:
                                # Regular image file processing
                                # Process image with PIL for high quality
                                if PIL_AVAILABLE:
                                    with PILImage.open(str(file_abs)) as pil_img:
                                        # Get original dimensions
                                        original_width, original_height = pil_img.size
                                        
                                        # Calculate maximum dimensions for PDF (reduced for smaller file size)
                                        max_width, max_height = 400, 300
                                        
                                        # Calculate scaling factor to maintain aspect ratio
                                        width_ratio = max_width / original_width
                                        height_ratio = max_height / original_height
                                        scale_ratio = min(width_ratio, height_ratio)
                                        
                                        # Calculate final dimensions for PDF
                                        pdf_width = original_width * scale_ratio
                                        pdf_height = original_height * scale_ratio
                                        
                                        # Convert to RGB if necessary
                                        if pil_img.mode in ('RGBA', 'LA', 'P'):
                                            rgb_img = PILImage.new('RGB', pil_img.size, (255, 255, 255))
                                            if pil_img.mode == 'P':
                                                pil_img = pil_img.convert('RGBA')
                                            rgb_img.paste(pil_img, mask=pil_img.split()[-1] if pil_img.mode in ('RGBA', 'LA') else None)
                                            pil_img = rgb_img
                                        
                                        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img:
                                            pil_img.save(temp_img.name, format='JPEG', quality=75, optimize=True, dpi=(150, 150))
                                            reportlab_img = ReportLabImage(temp_img.name, width=pdf_width, height=pdf_height)
                                            
                                            # Clean up temp file
                                            try:
                                                os.unlink(temp_img.name)
                                            except:
                                                pass
                                else:
                                    reportlab_img = ReportLabImage(str(file_abs), width=400, height=300)
                                    pdf_width, pdf_height = 400, 300
                            
                            # Create image with caption
                            file_type_label = "HTML File" if file_extension in ['html', 'htm'] else "Screenshot"
                            img_with_caption = [
                                [reportlab_img],
                                [Paragraph(f"<b>{file_type_label}:</b> {filename}", caption_style)]
                            ]
                            
                            img_table = Table(img_with_caption, colWidths=[pdf_width])
                            img_table.setStyle(TableStyle([
                                ('ALIGN', (0,0), (-1,-1), 'CENTER'),
                                ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                                ('LEFTPADDING', (0,0), (-1,-1), 0),
                                ('RIGHTPADDING', (0,0), (-1,-1), 0),
                                ('TOPPADDING', (0,0), (-1,0), 10),
                                ('BOTTOMPADDING', (0,0), (-1,0), 5),
                                ('TOPPADDING', (0,1), (-1,1), 5),
                                ('BOTTOMPADDING', (0,1), (-1,1), 15),
                            ]))
                            
                            elements.append(img_table)
                            elements.append(Spacer(1, 15))
                            
                        except Exception as e:
                            print(f"Error processing evidence file {file_path}: {e}")
                            # Create error info table
                            file_type = "HTML File" if file_extension in ['html', 'htm'] else "Screenshot"
                            error_info = [
                                [f"{file_type} #{idx}", f"Status: Error"],
                                [f"File: {filename}", f"Error: {str(e)[:50]}..."]
                            ]
                            
                            error_table = Table(error_info, colWidths=[200, 200])
                            error_table.setStyle(TableStyle([
                                ('FONTNAME', (0,0), (-1,-1), PDF_FONT_NORMAL),
                                ('FONTSIZE', (0,0), (-1,-1), 8),
                                ('ALIGN', (0,0), (-1,-1), 'CENTER'),
                                ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                                ('TEXTCOLOR', (0,0), (-1,-1), colors.HexColor("#B71C1C")),
                                ('BACKGROUND', (0,0), (-1,-1), colors.HexColor("#FFEBEE")),
                                ('GRID', (0,0), (-1,-1), 1, colors.HexColor("#B71C1C")),
                                ('TOPPADDING', (0,0), (-1,-1), 4),
                                ('BOTTOMPADDING', (0,0), (-1,-1), 4),
                                ('LEFTPADDING', (0,0), (-1,-1), 6),
                                ('RIGHTPADDING', (0,0), (-1,-1), 6),
                            ]))
                            
                            elements.append(error_table)
                            elements.append(Spacer(1, 10))
                    else:
                        # Create missing file info table
                        file_type = "HTML File" if file_extension in ['html', 'htm'] else "Screenshot"
                        missing_info = [
                            [f"{file_type} #{idx}", f"Status: Missing"],
                            [f"File: {filename}", f"Path: {file_path}"]
                        ]
                        
                        missing_table = Table(missing_info, colWidths=[200, 200])
                        missing_table.setStyle(TableStyle([
                            ('FONTNAME', (0,0), (-1,-1), PDF_FONT_NORMAL),
                            ('FONTSIZE', (0,0), (-1,-1), 8),
                            ('ALIGN', (0,0), (-1,-1), 'CENTER'),
                            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                            ('TEXTCOLOR', (0,0), (-1,-1), colors.HexColor("#FF9800")),
                            ('BACKGROUND', (0,0), (-1,-1), colors.HexColor("#FFF3E0")),
                            ('GRID', (0,0), (-1,-1), 1, colors.HexColor("#FF9800")),
                            ('TOPPADDING', (0,0), (-1,-1), 4),
                            ('BOTTOMPADDING', (0,0), (-1,-1), 4),
                            ('LEFTPADDING', (0,0), (-1,-1), 6),
                            ('RIGHTPADDING', (0,0), (-1,-1), 6),
                        ]))
                        
                        elements.append(missing_table)
                        elements.append(Spacer(1, 10))
            else:
                elements.append(Paragraph("No evidence files available for this test case.", normal_style))
        else:
            elements.append(PageBreak())
            elements.append(Paragraph("Test Evidence Files", header_style))
            elements.append(Spacer(1, 15))
            elements.append(Paragraph("No evidence files available for this test case.", normal_style))

        # Footer
        footer_style = styles['Normal'].clone('FooterStyle')
        footer_style.fontSize = 8
        footer_style.textColor = colors.HexColor("#666666")
        footer_style.fontName = PDF_FONT_NORMAL
        footer_style.leading = 10
        footer_style.alignment = 1
        
        elements.append(Spacer(1, 30))
        elements.append(Paragraph("_______________________________________________", footer_style))
        elements.append(Spacer(1, 10))
        elements.append(Paragraph("Generated by: Test Automation Dashboard v1.0", footer_style))
        elements.append(Paragraph(f"Report Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", footer_style))
        elements.append(Paragraph("Confidential - For Internal Use Only", footer_style))

        # Build PDF with enhanced error handling
        try:
            doc.build(elements)
            buffer.seek(0)
            return buffer
        except Exception as build_error:
            print(f"[ERROR] PDF build failed for {test_case_id}: {build_error}")
            # Create a simpler PDF with basic information if the full build fails
            try:
                buffer = io.BytesIO()
                doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=30, bottomMargin=30)
                simple_elements = []
                
                # Simple title
                simple_elements.append(Paragraph(f"Test Case: {test_case_id}", styles['Title']))
                simple_elements.append(Spacer(1, 20))
                
                # Simple status
                simple_elements.append(Paragraph(f"Status: {test_case_status}", styles['Normal']))
                simple_elements.append(Spacer(1, 10))
                
                # Simple description (without special formatting)
                if test_case_name and test_case_name != test_case_id:
                    clean_name = re.sub(r'[<>&"\']', '', str(test_case_name))
                    simple_elements.append(Paragraph(f"Description: {clean_name}", styles['Normal']))
                    simple_elements.append(Spacer(1, 10))
                
                # Simple error message (if any) - truncated and cleaned
                if fail_desc_text:
                    clean_error = re.sub(r'[<>&"\']', '', str(fail_desc_text)[:1000])  # Truncate to 1000 chars
                    simple_elements.append(Paragraph(f"Error Description: {clean_error}...", styles['Normal']))
                    simple_elements.append(Spacer(1, 10))
                
                simple_elements.append(Spacer(1, 20))
                simple_elements.append(Paragraph("Note: This is a simplified PDF due to formatting issues in the original content.", styles['Normal']))
                simple_elements.append(Paragraph(f"Original error: {str(build_error)[:200]}", styles['Normal']))
                
                doc.build(simple_elements)
                buffer.seek(0)
                return buffer
            except Exception as simple_error:
                print(f"[ERROR] Even simple PDF build failed for {test_case_id}: {simple_error}")
                raise build_error
        
    except Exception as e:
        print(f"Error generating test case PDF for {test_case_id}: {e.args}")
        return None

@app.route('/api/export_testcase_pdf', methods=['POST'])
def export_testcase_pdf():
    """Export individual test case to PDF with detailed screenshots and information."""
    if not REPORTLAB_AVAILABLE:
        print("[ERROR] ReportLab not available for PDF export")
        return jsonify({'error': 'PDF download not available. ReportLab not installed.'}), 500
        
    try:
        print("[DEBUG] Starting PDF export request...")
        data = request.get_json()
        if not data:
            print("[ERROR] No JSON data provided in request")
            return jsonify({'error': 'No data provided'}), 400
            
        test_case_id = data.get('test_case_id')
        test_case_desc = data.get('test_case_desc')
        feature_name = data.get('feature_name')
        run_timestamp = data.get('run_timestamp')
        
        print(f"[DEBUG] PDF export request params: test_case_id='{test_case_id}', feature_name='{feature_name}', run_timestamp='{run_timestamp}'")
        
        if not all([test_case_id, feature_name, run_timestamp]):
            print(f"[ERROR] Missing required parameters: test_case_id={test_case_id}, feature_name={feature_name}, run_timestamp={run_timestamp}")
            return jsonify({'error': 'Missing required parameters: test_case_id, feature_name, run_timestamp'}), 400

        # Find the specific test case data
        print(f"[DEBUG] Searching for test case data in {RESULTS_DIR}")
        all_excel_files = find_excel_files(RESULTS_DIR)
        print(f"[DEBUG] Found {len(all_excel_files)} Excel files to search")
        target_feature_data = None
        
        for excel_file in all_excel_files:
            print(f"[DEBUG] Parsing Excel file: {excel_file}")
            feature_data = parse_excel_data(excel_file)
            if feature_data:
                print(f"[DEBUG] Excel file data: feature_name='{feature_data.get('feature_name')}', run_timestamp='{feature_data.get('run_timestamp')}'")
                if (feature_data.get("feature_name") == feature_name and 
                    feature_data.get("run_timestamp") == run_timestamp):
                    target_feature_data = feature_data
                    print(f"[DEBUG] Found matching feature data in {excel_file}")
                    break
            else:
                print(f"[DEBUG] Failed to parse Excel file: {excel_file}")
        
        if not target_feature_data:
            print(f"[ERROR] Test case not found: {test_case_id} in {feature_name} for timestamp {run_timestamp}")
            return jsonify({'error': f'Test case not found: {test_case_id} in {feature_name}'}), 404

        # Get Excel file for test case details
        #excel_path = PROJECT_ROOT / target_feature_data['excel_path']
        #print(f"[DEBUG] Reading Excel file: {excel_path}")
        #if not excel_path.exists():
        #    print(f"[ERROR] Excel file not found: {excel_path}")
        #    return jsonify({'error': f'Excel file not found: {excel_path}'}), 404
            
        df = pd.read_excel(excel_file)
        print(f"[DEBUG] Excel file loaded successfully. Shape: {df.shape}")
        print(f"[DEBUG] Available columns: {list(df.columns)}")
        
        # Find relevant columns
        id_columns = ['Test Case ID', 'TestCaseID', 'Test Case', 'ID', 'TestCase', 'TestCaseNo', 'Name']
        id_col = find_first_column(df.columns, id_columns)
        
        desc_columns = ['Test Case Description', 'TestCaseDescription', 'Description', 'Test Description', 'Name', 'TestCaseDesc']
        desc_col = find_first_column(df.columns, desc_columns)
        
        status_columns = ['TestResult', 'Status', 'Result']
        status_col = find_first_column(df.columns, status_columns)
        
        error_columns = ['Fail_Description', 'Fail Description', 'TestResult Description', 'Result Description', 'Error', 'Message', 'Failure Reason']
        error_col = find_first_column(df.columns, error_columns)
        
        expected_result_columns = ['ExpectedResult', 'Expected Result', 'Expected', 'Expected Outcome']
        expected_result_col = find_first_column(df.columns, expected_result_columns)
        
        print(f"[DEBUG] Column mapping: id_col='{id_col}', desc_col='{desc_col}', status_col='{status_col}', error_col='{error_col}', expected_result_col='{expected_result_col}'")
        
        # Find the specific test case row
        test_case_row = None
        print(f"[DEBUG] Searching for test case ID: '{test_case_id}'")
        for _, row in df.iterrows():
            row_id = str(row.get(id_col, '')).strip()
            if row_id == test_case_id:
                test_case_row = row
                print(f"[DEBUG] Found test case row for ID: '{test_case_id}'")
                
                # Debug the content length
                if error_col and error_col in row:
                    error_content = str(row[error_col]) if pd.notna(row[error_col]) else ''
                    print(f"[DEBUG] Error content length: {len(error_content)} characters")
                    if len(error_content) > 1000:
                        print(f"[DEBUG] Long error content detected. First 200 chars: {error_content[:200]}...")
                        print(f"[DEBUG] Contains Thai characters: {any(ord(c) > 127 for c in error_content)}")
                break
        
        if test_case_row is None:
            # Try to find by partial match or use default values
            print(f"Test case {test_case_id} not found in Excel, using default values")
            test_case_row = {
                id_col: test_case_id,
                desc_col: test_case_id,
                status_col: 'UNKNOWN',
                error_col: '',
                expected_result_col: ''
            }

        # Use core PDF generation function
        print(f"[DEBUG] Calling PDF generation for test case: {test_case_id}")
        try:
            pdf_buffer = generate_test_case_pdf_core(test_case_id, feature_name, run_timestamp, target_feature_data, test_case_row)
            print(f"[DEBUG] PDF generation completed. Buffer exists: {pdf_buffer is not None}")
        except Exception as pdf_error:
            print(f"[ERROR] PDF generation failed with error: {pdf_error}")
            import traceback
            traceback.print_exc()
            return jsonify({'error': f'PDF generation failed: {str(pdf_error)}'}), 500
        
        if not pdf_buffer:
            print(f"[ERROR] PDF generation returned None for test case: {test_case_id}")
            return jsonify({'error': 'Failed to generate PDF - buffer is None'}), 500
        
        # Generate filename (sanitize to avoid header/path issues)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_tc = sanitize_filename(test_case_id)
        safe_feature = sanitize_filename(feature_name)
        filename = f"TestCase_{safe_tc}_{safe_feature}_{timestamp}.pdf"
        print(f"[DEBUG] Generated filename: {filename}")
        
        try:
            pdf_size = len(pdf_buffer.getvalue())
            print(f"[DEBUG] Sending PDF file. Buffer size: {pdf_size} bytes ({pdf_size / (1024*1024):.2f} MB)")
            
            # Check if PDF is too large (> 100 MB)
            if pdf_size > 100 * 1024 * 1024:  # 100 MB limit
                print(f"[WARNING] PDF is too large ({pdf_size / (1024*1024):.2f} MB), creating optimized version")
                
                # Create a simpler PDF with reduced content using optimized mode
                try:
                    optimized_buffer = generate_test_case_pdf_core(test_case_id, feature_name, run_timestamp, target_feature_data, test_case_row, mode='optimized')
                    if optimized_buffer:
                        opt_size = len(optimized_buffer.getvalue())
                        print(f"[DEBUG] Optimized PDF size: {opt_size} bytes ({opt_size / (1024*1024):.2f} MB)")
                        return send_file(optimized_buffer, as_attachment=True, download_name=filename, mimetype='application/pdf')
                except Exception as opt_error:
                    print(f"[ERROR] Failed to create optimized PDF: {opt_error}")
                
                # If optimization fails, return error
                return jsonify({'error': f'PDF is too large ({pdf_size / (1024*1024):.2f} MB). Please contact administrator.'}), 413
            
            return send_file(pdf_buffer, as_attachment=True, download_name=filename, mimetype='application/pdf')
        except Exception as send_error:
            print(f"[ERROR] Failed to send PDF file: {send_error}")
            import traceback
            traceback.print_exc()
            return jsonify({'error': f'Failed to send PDF: {str(send_error)}'}), 500
        
    except Exception as e:
        print(f"[ERROR] Test Case PDF Export Error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'Export failed: {str(e)}'}), 500

@app.route('/api/export_feature_pdfs_zip', methods=['POST'])
def export_feature_pdfs_zip():
    """Export all test case PDFs for a specific feature as a ZIP file."""
    if not REPORTLAB_AVAILABLE:
        return jsonify({'error': 'PDF generation not available. ReportLab not installed.'}), 500
        
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        feature_name = data.get('feature_name')
        run_timestamp = data.get('run_timestamp')
        run_index = data.get('run_index')
        feature_index = data.get('feature_index')
        
        if not all([feature_name, run_timestamp]):
            return jsonify({'error': 'Missing required parameters'}), 400

        # Find the specific feature data
        all_excel_files = find_excel_files(RESULTS_DIR)
        target_feature_data = None
        
        for excel_file in all_excel_files:
            feature_data = parse_excel_data(excel_file)
            if (feature_data and 
                feature_data.get("feature_name") == feature_name and 
                feature_data.get("run_timestamp") == run_timestamp):
                target_feature_data = feature_data
                break
        
        if not target_feature_data:
            return jsonify({'error': f'Feature not found: {feature_name}'}), 404

        # Get Excel file for test case details
        excel_path = PROJECT_ROOT / target_feature_data['excel_path']
        if not excel_path.exists():
            return jsonify({'error': f'Excel file not found: {excel_path}'}), 404
            
        df = pd.read_excel(excel_path)
        
        # Find relevant columns
        id_columns = ['Test Case ID', 'TestCaseID', 'Test Case', 'ID', 'TestCase', 'TestCaseNo', 'Name']
        id_col = find_first_column(df.columns, id_columns)
        status_columns = ['TestResult', 'Status', 'Result']
        status_col = find_first_column(df.columns, status_columns)
        
        if not id_col or not status_col:
            return jsonify({'error': 'Required columns not found in Excel file'}), 400

        # Filter for executed tests only (Execute == 'Y')
        execute_column = next((c for c in df.columns if c.lower() == 'execute'), None)
        if execute_column:
            df = df[df[execute_column].str.lower() == 'y'].copy()

        # Create temporary ZIP file
        pdf_count = 0
        with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as temp_zip:
            with zipfile.ZipFile(temp_zip.name, 'w', zipfile.ZIP_DEFLATED) as zipf:
                
                # Process each test case that has Execute = 'Y'
                for _, row in df.iterrows():
                    test_case_id = str(row.get(id_col, '')).strip()
                    test_case_status = str(row.get(status_col, '')).strip().upper()
                    
                    # Skip if test case is empty
                    if not test_case_id or test_case_id.lower() in ['nan', 'none', '']:
                        continue
                    
                    try:
                        # Generate PDF for this test case (include all, regardless of status)
                        pdf_buffer = generate_test_case_pdf_core(
                            test_case_id, feature_name, run_timestamp, target_feature_data, row
                        )
                        
                        if pdf_buffer:
                            # Ensure buffer is at the beginning and get content
                            pdf_buffer.seek(0)
                            pdf_content = pdf_buffer.getvalue()
                            
                            # Validate PDF content is not empty
                            if pdf_content and len(pdf_content) > 0:
                                # Add PDF to ZIP
                                filename = f"{sanitize_filename(test_case_id)}_{sanitize_filename(feature_name)}.pdf"
                                zipf.writestr(filename, pdf_content)
                                pdf_count += 1
                                print(f"Added PDF for test case: {test_case_id} (size: {len(pdf_content)} bytes)")
                            else:
                                print(f"PDF content is empty for test case: {test_case_id}")
                        else:
                            print(f"Failed to generate PDF for test case: {test_case_id}")
                            
                    except Exception as e:
                        print(f"Error generating PDF for test case {test_case_id}: {e}")
                        import traceback
                        traceback.print_exc()
                        continue

        # Read the ZIP file and return it
        with open(temp_zip.name, 'rb') as zip_file:
            zip_data = zip_file.read()
        
        # Clean up temporary file
        os.unlink(temp_zip.name)
        
        # Validate ZIP content is not empty
        if not zip_data or len(zip_data) == 0:
            print(f"[ERROR] ZIP file is empty for feature: {feature_name}")
            return jsonify({'error': 'Generated ZIP file is empty. No valid test cases found or PDF generation failed.'}), 500
        
        print(f"[DEBUG] ZIP file created successfully for feature: {feature_name}, size: {len(zip_data)} bytes, PDFs included: {pdf_count}")
        
        # Generate filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{sanitize_filename(feature_name)}_AllTestCases_{timestamp}.zip"
        
        return send_file(
            io.BytesIO(zip_data),
            as_attachment=True,
            download_name=filename,
            mimetype='application/zip'
        )
        
    except Exception as e:
        print(f"ZIP Export Error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/export_latest_all_features_zip', methods=['POST'])
def export_latest_all_features_zip():
    """Export all test case PDFs for all features in the latest run as a ZIP file."""
    if not REPORTLAB_AVAILABLE:
        return jsonify({'error': 'PDF generation not available. ReportLab not installed.'}), 500
        
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        run_timestamp = data.get('run_timestamp')
        features = data.get('features', [])
        
        if not run_timestamp or not features:
            return jsonify({'error': 'Missing required parameters'}), 400

        try:
            # Create ZIP in memory
            total_pdf_count = 0
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                
                    # Process each feature
                    for feature in features:
                        feature_name = feature.get('name')
                        excel_path = feature.get('excel_path')
                        
                        if not feature_name or not excel_path:
                            continue
                        
                        # Find the specific feature data
                        full_excel_path = PROJECT_ROOT / excel_path
                        if not full_excel_path.exists():
                            print(f"Excel file not found: {full_excel_path}")
                            continue
                            
                        try:
                            df = pd.read_excel(full_excel_path)
                            
                            # Find relevant columns
                            id_columns = ['Test Case ID', 'TestCaseID', 'Test Case', 'ID', 'TestCase', 'TestCaseNo', 'Name']
                            id_col = find_first_column(df.columns, id_columns)
                            status_columns = ['TestResult', 'Status', 'Result']
                            status_col = find_first_column(df.columns, status_columns)
                            
                            if not id_col or not status_col:
                                print(f"Required columns not found in Excel file: {excel_path}")
                                continue

                            # Filter for executed tests only (Execute == 'Y')
                            df = filter_executed_rows(df)

                            # Create feature folder in ZIP
                            feature_folder = f"{feature_name}/"
                            
                            # Process each test case that has Execute = 'Y'
                            for _, row in df.iterrows():
                                test_case_id = str(row.get(id_col, '')).strip()
                                test_case_status = str(row.get(status_col, '')).strip().upper()
                                
                                # Skip if test case is empty
                                if not test_case_id or test_case_id.lower() in ['nan', 'none', '']:
                                    continue
                                
                                try:
                                    # Generate PDF for this test case
                                    # Build parsed_feature per feature (once outside loop would be better, but safe here)
                                    try:
                                        parsed_feature = parse_excel_data(str(full_excel_path))
                                    except Exception:
                                        parsed_feature = {'feature_name': feature_name, 'excel_path': excel_path, 'test_evidence': {}}
                                    pdf_buffer = generate_test_case_pdf_core(
                                        test_case_id, feature_name, run_timestamp, parsed_feature, row
                                    )
                                    
                                    if pdf_buffer:
                                        # Ensure buffer is at the beginning and get content
                                        pdf_buffer.seek(0)
                                        pdf_content = pdf_buffer.getvalue()
                                        
                                        # Validate PDF content is not empty
                                        if pdf_content and len(pdf_content) > 0:
                                            # Add PDF to ZIP with feature folder structure
                                            filename = f"{feature_folder}{sanitize_filename(test_case_id)}.pdf"
                                            zipf.writestr(filename, pdf_content)
                                            total_pdf_count += 1
                                            print(f"Added PDF for test case: {test_case_id} in feature: {feature_name} (size: {len(pdf_content)} bytes)")
                                        else:
                                            print(f"PDF content is empty for test case: {test_case_id}")
                                    else:
                                        print(f"Failed to generate PDF for test case: {test_case_id}")
                                        
                                except Exception as e:
                                    print(f"Error generating PDF for test case {test_case_id}: {e}")
                                    import traceback
                                    traceback.print_exc()
                                    continue
                                    
                        except Exception as e:
                            print(f"Error processing feature {feature_name}: {e}")
                            continue

            # Get the ZIP data from memory buffer
            zip_buffer.seek(0)
            zip_data = zip_buffer.getvalue()
            
            # Validate ZIP content is not empty
            if not zip_data or len(zip_data) == 0:
                print(f"[ERROR] ZIP file is empty for all features export")
                return jsonify({'error': 'Generated ZIP file is empty. No valid test cases found or PDF generation failed.'}), 500
            
            print(f"[DEBUG] ZIP file created successfully for all features, size: {len(zip_data)} bytes, total PDFs included: {total_pdf_count}")
            
            # Generate filename
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"LatestRun_AllFeatures_{timestamp}.zip"
            
            return send_file(
                io.BytesIO(zip_data),
                as_attachment=True,
                download_name=filename,
                mimetype='application/zip'
            )
                
        except Exception as e:
            print(f"Error during PDF generation: {e}")
            import traceback
            traceback.print_exc()
            return jsonify({'error': f'PDF generation failed: {str(e)}'}), 500
        
    except Exception as e:
        print(f"Latest All Features ZIP Export Error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/test_pdf_generation', methods=['GET'])
def test_pdf_generation():
    """Test PDF generation functionality to diagnose issues."""
    try:
        # Check if ReportLab is available
        if not REPORTLAB_AVAILABLE:
            return jsonify({
                'status': 'error',
                'message': 'ReportLab not installed',
                'reportlab_available': False
            }), 500
        
        # Test basic PDF creation
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        elements = []
        
        # Add test content
        title = Paragraph("PDF Generation Test", styles['Title'])
        elements.append(title)
        elements.append(Spacer(1, 20))
        
        content = Paragraph("This is a test PDF to verify PDF generation is working correctly.", styles['Normal'])
        elements.append(content)
        elements.append(Spacer(1, 20))
        
        # Add Thai text test
        thai_text = Paragraph(f"à¸—à¸”à¸ªà¸­à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal'])
        elements.append(thai_text)
        
        # Build PDF
        doc.build(elements)
        buffer.seek(0)
        pdf_size = len(buffer.getvalue())
        
        return jsonify({
            'status': 'success',
            'message': 'PDF generation test successful',
            'reportlab_available': True,
            'pdf_size': pdf_size,
            'fonts': {
                'normal': PDF_FONT_NORMAL,
                'bold': PDF_FONT_BOLD
            }
        })
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[ERROR] PDF generation test failed: {e}")
        print(f"[ERROR] Traceback: {error_details}")
        
        return jsonify({
            'status': 'error',
            'message': str(e),
            'error_details': error_details,
            'reportlab_available': REPORTLAB_AVAILABLE
        }), 500

@app.route('/api/test_pdf_download', methods=['GET'])
def test_pdf_download():
    """Test PDF download functionality."""
    try:
        if not REPORTLAB_AVAILABLE:
            return jsonify({'error': 'ReportLab not installed'}), 500
        
        # Create test PDF
        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        elements = []
        
        # Add test content
        title = Paragraph("Test PDF Download", styles['Title'])
        elements.append(title)
        elements.append(Spacer(1, 20))
        
        content = Paragraph(f"Test PDF created at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal'])
        elements.append(content)
        elements.append(Spacer(1, 20))
        
        thai_content = Paragraph("à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸” PDF à¸ à¸²à¸©à¸²à¹„à¸—à¸¢", styles['Normal'])
        elements.append(thai_content)
        
        # Build and return PDF
        doc.build(elements)
        buffer.seek(0)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"test_pdf_{timestamp}.pdf"
        
        return send_file(
            buffer,
            as_attachment=True,
            download_name=filename,
            mimetype='application/pdf'
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': f'Test PDF download failed: {str(e)}'}), 500

# @app.route('/api/system_status', methods=['GET'])
# def system_status():
#     """Check system status for PDF generation."""
#     try:
#         status = {
#             'reportlab_available': REPORTLAB_AVAILABLE,
#             'matplotlib_available': MATPLOTLIB_AVAILABLE,
#             'project_root': str(PROJECT_ROOT),
#             'results_dir': str(RESULTS_DIR),
#             'pdf_fonts': {
#                 'normal': PDF_FONT_NORMAL,
#                 'bold': PDF_FONT_BOLD
#             }
#         }
        
#         # Check if results directory exists and has files
#         if RESULTS_DIR.exists():
#             excel_files = find_excel_files(RESULTS_DIR)
#             status['results_dir_exists'] = True
#             status['excel_files_count'] = len(excel_files)
#             status['sample_excel_files'] = [str(f) for f in excel_files[:5]]  # Show first 5
#         else:
#             status['results_dir_exists'] = False
#             status['excel_files_count'] = 0
        
#         # Test basic imports
#         try:
#             if REPORTLAB_AVAILABLE:
#                 from reportlab.lib.pagesizes import A4
#                 status['reportlab_imports'] = 'success'
#             else:
#                 status['reportlab_imports'] = 'failed'
#         except Exception as e:
#             status['reportlab_imports'] = f'failed: {str(e)}'
        
#         return jsonify(status)
        
#     except Exception as e:
#         import traceback
#         return jsonify({
#             'error': str(e),
#             'traceback': traceback.format_exc()
#         }), 500

def format_timestamp_professional(timestamp_str):
    """Format timestamp professionally (helper function)."""
    try:
        if timestamp_str and len(timestamp_str) >= 15:
            if timestamp_str[8] in ['-', '_']:
                year = timestamp_str[:4]
                month = timestamp_str[4:6]
                day = timestamp_str[6:8]
                hour = timestamp_str[9:11]
                minute = timestamp_str[11:13]
                second = timestamp_str[13:15]
                
                dt = datetime(int(year), int(month), int(day), int(hour), int(minute), int(second))
                return dt.strftime("%B %d, %Y at %I:%M %p")
            else:
                dt = datetime.fromisoformat(timestamp_str.replace('T', ' '))
                return dt.strftime("%B %d, %Y at %I:%M %p")
        else:
            return timestamp_str
    except:
        return timestamp_str

# --- Static File and Results Serving ---
# This route serves images and other files from the 'results' directory
@app.route('/results/<path:filepath>')
def serve_results(filepath):
    return send_from_directory(RESULTS_DIR, filepath)

# --- HTML Thumbnail Generation (cached) ---
def _ensure_thumbnail_dir(html_path: Path = None) -> Path:
    """Ensure thumbnail directory exists. If html_path is provided, create a subdirectory 
    based on the test case folder structure to prevent cross-contamination.
    
    NEW STRUCTURE: results/YYYYMMDD_HHMMSS/FeatureName/TestCaseID/.thumbnails/
    """
    if html_path:
        # Create thumbnail directory structure that mirrors the test case folder structure
        # Example: results/20241201_120000/Feature1/TC001/file.html -> results/20241201_120000/Feature1/TC001/.thumbnails/
        try:
            # Get the relative path from results directory
            rel_path = html_path.relative_to(RESULTS_DIR)
            # Create thumbnail subdirectory structure INSIDE the test case folder
            thumb_subdir = RESULTS_DIR / rel_path.parent / ".thumbnails"
            thumb_subdir.mkdir(parents=True, exist_ok=True)
            print(f"[INFO] Created thumbnail directory: {thumb_subdir}")
            return thumb_subdir
        except Exception as e:
            print(f"[ERROR] Could not create structured thumbnail directory: {e}")
            raise Exception(f"Failed to create thumbnail directory for {html_path}: {e}")
    
    # NO FALLBACK: Only structured thumbnails are allowed
    raise Exception("html_path is required for structured thumbnail directory creation")

def _get_thumbnail_path(html_path: Path) -> Path:
    """Generate a thumbnail path that maintains the folder structure of the original file.
    This prevents cross-contamination between different test cases.
    
    NEW STRUCTURE: results/YYYYMMDD_HHMMSS/FeatureName/TestCaseID/.thumbnails/file_hash.png
    """
    try:
        # Get the relative path from results directory
        rel_path = html_path.relative_to(RESULTS_DIR)
        # Create thumbnail path that mirrors the original structure INSIDE test case folder
        thumb_dir = _ensure_thumbnail_dir(html_path)
        
        # Create a unique filename based on the full path
        # Use hash of the full path to ensure uniqueness
        import hashlib
        path_hash = hashlib.md5(str(html_path).encode()).hexdigest()[:8]
        filename = f"{html_path.stem}_{path_hash}.png"
        
        return thumb_dir / filename
    except Exception as e:
        print(f"[ERROR] Could not create structured thumbnail path: {e}")
        # NO FALLBACK: Only structured thumbnails are allowed
        raise Exception(f"Failed to generate structured thumbnail path for {html_path}: {e}")

def _html_to_thumbnail(html_abs_path: Path, thumb_abs_path: Path = None, width: int = 800, height: int = 450):
    """Generate a PNG thumbnail for an HTML file using Playwright if available.
    Falls back to a simple placeholder PNG if Playwright is unavailable or errors occur.
    
    Args:
        html_abs_path: Path to the HTML file
        thumb_abs_path: Path where to save the thumbnail (if None, will be auto-generated)
        width: Thumbnail width
        height: Thumbnail height
    """
    # Auto-generate thumbnail path if not provided
    if thumb_abs_path is None:
        thumb_abs_path = _get_thumbnail_path(html_abs_path)
    
    print(f"[INFO] Generating thumbnail for {html_abs_path}")
    print(f"[INFO] Thumbnail will be saved to: {thumb_abs_path}")
    print(f"[DEBUG] PLAYWRIGHT_AVAILABLE = {PLAYWRIGHT_AVAILABLE}")
    print(f"[DEBUG] PIL_AVAILABLE = {PIL_AVAILABLE}")
    
    # REMOVED REDUNDANT CODE: thumb_abs_path.parent.mkdir(parents=True, exist_ok=True)
    # This is already handled by _ensure_thumbnail_dir() in _get_thumbnail_path()
    
    # Try Playwright first (best quality)
    if PLAYWRIGHT_AVAILABLE:
        try:
            print(f"[INFO] Attempting Playwright HTML capture...")
            playwright = sync_playwright().start()
            try:
                browser = playwright.chromium.launch(
                    executable_path=str(chrome_path / "chrome.exe"),
                    headless=True
                )
                page = browser.new_page(viewport={"width": width, "height": height})

                # Build file URI for local HTML
                file_uri = f"file:///{html_abs_path.as_posix().replace(chr(92), chr(47))}"
                print(f"[INFO] Using file URI: {file_uri}")

                page.goto(file_uri, wait_until="load")
                page.wait_for_timeout(1000)

                # Full page to ensure content captured
                page.screenshot(path=str(thumb_abs_path), full_page=True, type='png')
                browser.close()

                if thumb_abs_path.exists() and thumb_abs_path.stat().st_size > 10000:
                    print(f"[INFO] Successfully generated HTML thumbnail with Playwright: {thumb_abs_path}")
                    return True
                else:
                    print(f"[WARN] Screenshot created but seems empty or too small")
                    if thumb_abs_path.exists():
                        thumb_abs_path.unlink()
                    raise Exception("Screenshot file is empty or too small")
            finally:
                playwright.stop()
        except Exception as e:
            print(f"[WARN] Playwright thumbnail failed for {html_abs_path}: {e}")
            print(f"[WARN] Error type: {type(e).__name__}")
            print(f"[WARN] Error details: {str(e)}")
    
    # Fallback: generate a simple placeholder PNG via Pillow
    if PIL_AVAILABLE:
        try:
            print(f"[INFO] Using Pillow fallback for HTML thumbnail...")
            img = PILImage.new("RGB", (width, height), color=(245, 247, 250))
            draw = ImageDraw.Draw(img)
            
            # Create a more attractive placeholder
            # Background rectangle
            draw.rectangle([(20, 20), (width-20, height-20)], fill=(255, 255, 255), outline=(220, 220, 220), width=2)
            
            # HTML icon representation
            icon_color = (74, 144, 226)  # Blue color for HTML
            draw.rectangle([(width//2-40, height//2-60), (width//2+40, height//2-20)], fill=icon_color)
            draw.text((width//2, height//2-40), "HTML", fill=(255, 255, 255), anchor="mm")
            
            # Text
            try:
                font = ImageFont.load_default()
            except Exception:
                font = None
            
            # Main text
            draw.text((width//2, height//2+20), "HTML Preview", fill=(64, 64, 64), font=font, anchor="mm")
            
            # Filename (truncated if too long)
            filename = html_abs_path.name
            if len(filename) > 30:
                filename = filename[:27] + "..."
            draw.text((width//2, height//2+50), filename, fill=(96, 96, 96), font=font, anchor="mm")
            
            # Add warning text
            draw.text((width//2, height//2+80), "Playwright not available", fill=(255, 100, 100), font=font, anchor="mm")
            draw.text((width//2, height//2+100), "Install: pip install playwright", fill=(255, 100, 100), font=font, anchor="mm")
            
            img.save(str(thumb_abs_path), format="PNG", optimize=True)
            print(f"[INFO] Generated fallback HTML thumbnail with Pillow: {thumb_abs_path}")
            return True
        except Exception as e:
            print(f"[WARN] Pillow fallback thumbnail failed for {html_abs_path}: {e}")

    # Last resort: create a very basic placeholder
    if PIL_AVAILABLE:
        try:
            print(f"[INFO] Using last resort placeholder...")
            # Create a simple colored rectangle as placeholder
            img = PILImage.new("RGB", (width, height), color=(240, 240, 240))
            draw = ImageDraw.Draw(img)
            draw.rectangle([(0, 0), (width, height)], fill=(200, 200, 200), outline=(150, 150, 150), width=3)
            draw.text((width//2, height//2), "HTML", fill=(100, 100, 100), anchor="mm")
            img.save(str(thumb_abs_path), format="PNG")
            print(f"[INFO] Generated basic HTML placeholder: {thumb_abs_path}")
            return True
        except Exception as e:
            print(f"[ERROR] Failed to create any HTML thumbnail for {html_abs_path}: {e}")
    
    print(f"[ERROR] No thumbnail generation method available for {html_abs_path}")
    return False

def _html_preview_placeholder_svg(filename: str, width: int = 800, height: int = 450) -> bytes:
    """Return a lightweight SVG placeholder for HTML preview thumbnails.
    This does not require any external dependencies and guarantees a visual thumbnail.
    """
    safe_name = (filename or "HTML Preview").replace("<", "&lt;").replace(">", "&gt;")
    svg = f'''<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">
  <defs>
    <linearGradient id="g" x1="0" y1="0" x2="1" y2="1">
      <stop offset="0%" stop-color="#f5f7fa"/>
      <stop offset="100%" stop-color="#e4e7eb"/>
    </linearGradient>
  </defs>
  <rect width="100%" height="100%" fill="url(#g)"/>
  <rect x="20" y="20" width="{width-40}" height="{height-40}" fill="#ffffff" stroke="#dfe3e8" stroke-width="2" rx="10"/>
  <g font-family="Arial, Helvetica, sans-serif" text-anchor="middle">
    <text x="50%" y="48%" fill="#6b7280" font-size="28">HTML Preview</text>
    <text x="50%" y="58%" fill="#9ca3af" font-size="16">{safe_name}</text>
  </g>
</svg>'''
    return svg.encode("utf-8")

def _excel_preview_placeholder_svg(filename: str, width: int = 800, height: int = 450) -> bytes:
    """Return a lightweight SVG placeholder for Excel file preview thumbnails.
    This creates an Excel icon with filename for visual representation.
    """
    safe_name = (filename or "Excel File").replace("<", "&lt;").replace(">", "&gt;")
    svg = f'''<svg xmlns="http://www.w3.org/2000/svg" width="{width}" height="{height}">
  <defs>
    <linearGradient id="excel_g" x1="0" y1="0" x2="1" y2="1">
      <stop offset="0%" stop-color="#217346"/>
      <stop offset="100%" stop-color="#1e6b3d"/>
    </linearGradient>
  </defs>
  <rect width="100%" height="100%" fill="url(#excel_g)"/>
  <rect x="20" y="20" width="{width-40}" height="{height-40}" fill="#ffffff" stroke="#217346" stroke-width="2" rx="10"/>
  
  <!-- Excel Icon -->
  <g transform="translate({width//2 - 40}, {height//2 - 60})">
    <!-- Excel Sheet -->
    <rect x="0" y="0" width="80" height="100" fill="#ffffff" stroke="#217346" stroke-width="2"/>
    <!-- Excel Grid Lines -->
    <line x1="0" y1="20" x2="80" y2="20" stroke="#217346" stroke-width="1"/>
    <line x1="0" y1="40" x2="80" y2="40" stroke="#217346" stroke-width="1"/>
    <line x1="0" y1="60" x2="80" y2="60" stroke="#217346" stroke-width="1"/>
    <line x1="0" y1="80" x2="80" y2="80" stroke="#217346" stroke-width="1"/>
    <line x1="20" y1="0" x2="20" y2="100" stroke="#217346" stroke-width="1"/>
    <line x1="40" y1="0" x2="40" y2="100" stroke="#217346" stroke-width="1"/>
    <line x1="60" y1="0" x2="60" y2="100" stroke="#217346" stroke-width="1"/>
    <!-- Excel Logo -->
    <rect x="25" y="25" width="30" height="15" fill="#217346"/>
    <text x="40" y="35" fill="#ffffff" font-family="Arial, sans-serif" font-size="12" text-anchor="middle" font-weight="bold">X</text>
  </g>
  
  <!-- Filename -->
  <g font-family="Arial, Helvetica, sans-serif" text-anchor="middle">
    <text x="50%" y="85%" fill="#ffffff" font-size="16" font-weight="bold">Excel File</text>
    <text x="50%" y="95%" fill="#ffffff" font-size="12">{safe_name[:30]}</text>
  </g>
</svg>'''
    return svg.encode("utf-8")

@app.route('/api/evidence_thumbnail')
def api_evidence_thumbnail():
    """Return (and cache) a thumbnail for evidence files (HTML, Excel, Images).
    Query param 'path' must be a project-root-relative path like 'results/..../file.html'.
    """
    rel_path = request.args.get('path')
    if not rel_path:
        return abort(400, description="Missing 'path' query parameter")

    # Normalize and validate path
    try:
        # Strip leading slashes if provided
        rel_path_norm = rel_path.lstrip('/\\')
        # Join against RESULTS_DIR parent so 'results/...' resolves to the correct tree
        abs_path = (RESULTS_DIR.parent / rel_path_norm).resolve()
        if RESULTS_DIR not in abs_path.parents and abs_path != RESULTS_DIR:
            return abort(400, description="Path must be under results directory")
        
        # Check file extension
        file_ext = abs_path.suffix.lower()
        if file_ext not in ['.html', '.htm', '.xlsx', '.xls', '.png', '.jpg', '.jpeg', '.gif', '.bmp']:
            return abort(404, description="Unsupported file type")
            
        if not abs_path.exists():
            return abort(404)
    except Exception:
        return abort(400, description="Invalid path")

    # For Excel files, return SVG placeholder directly
    if file_ext in ['.xlsx', '.xls']:
        placeholder = _excel_preview_placeholder_svg(abs_path.name)
        return send_file(io.BytesIO(placeholder), mimetype='image/svg+xml')

    # For HTML files, generate thumbnail with better error handling
    if file_ext in ['.html', '.htm']:
        # Generate thumbnail path that maintains folder structure
        thumb_path = _get_thumbnail_path(abs_path)
        
        # Regenerate thumbnail if missing or outdated
        try:
            source_mtime = abs_path.stat().st_mtime
            need_build = True
            if thumb_path.exists():
                thumb_mtime = thumb_path.stat().st_mtime
                need_build = thumb_mtime < source_mtime
                
            if need_build:
                print(f"[INFO] Generating thumbnail for {abs_path}")
                print(f"[INFO] Using structured thumbnail path: {thumb_path}")
                # Generate synchronously to ensure we have something to serve
                thumbnail_success = _html_to_thumbnail(abs_path, thumb_path)
                
                # Verify thumbnail was created successfully
                if not thumbnail_success or not thumb_path.exists():
                    print(f"[WARN] Thumbnail generation failed for {abs_path}")
                    # Return SVG placeholder as fallback
                    placeholder = _html_preview_placeholder_svg(abs_path.name)
                    return send_file(io.BytesIO(placeholder), mimetype='image/svg+xml')
                    
        except Exception as e:
            print(f"[ERROR] Error preparing thumbnail for {abs_path}: {e}")
            # Return SVG placeholder as fallback
            placeholder = _html_preview_placeholder_svg(abs_path.name)
            return send_file(io.BytesIO(placeholder), mimetype='image/svg+xml')

        if thumb_path.exists():
            try:
                response = send_file(str(thumb_path), mimetype='image/png')
                response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
                response.headers['Pragma'] = 'no-cache' 
                response.headers['Expires'] = '0'
                return response
            except Exception as e:
                print(f"[ERROR] Error serving thumbnail {thumb_path}: {e}")
                # Return SVG placeholder as fallback
                placeholder = _html_preview_placeholder_svg(abs_path.name)
                return send_file(io.BytesIO(placeholder), mimetype='image/svg+xml')
        else:
            # Last-resort: return an inline SVG placeholder so UI always shows something
            placeholder = _html_preview_placeholder_svg(abs_path.name)
            return send_file(io.BytesIO(placeholder), mimetype='image/svg+xml')

    # For image files, return the image directly (resized if needed)
    if file_ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
        return send_file(str(abs_path), mimetype=f'image/{file_ext[1:]}')

    # Fallback
    return abort(404, description="Unsupported file type")

# Keep backward compatibility
@app.route('/api/html_thumbnail')
def api_html_thumbnail():
    """Legacy endpoint for HTML thumbnails - redirects to evidence_thumbnail."""
    return api_evidence_thumbnail()

def open_browser():
    """Function to open the browser to the dashboard URL."""
    print(">>> [DEBUG] Attempting to open web browser...")
    webbrowser.open_new("http://127.0.0.1:5000")

# --- HTML to Image Conversion for PDF ---
def html_to_image_for_pdf(html_abs_path: Path, width: int = 800, height: int = 600, full_page: bool = True):
    """Convert HTML file to image for PDF display using Playwright.
    Returns a PIL Image object that can be used in ReportLab PDF.
    
    Args:
        html_abs_path: Path to HTML file
        width: Viewport width
        height: Viewport height  
        full_page: Whether to capture full page (True) or just viewport (False)
    """
    try:
        if PLAYWRIGHT_AVAILABLE:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    executable_path=str(chrome_path / "chrome.exe"),
                    headless=True
                )
                
                # Use larger viewport for better content rendering
                viewport_width = max(width, 1200)  # Minimum 1200px width
                viewport_height = max(height, 800)  # Minimum 800px height
                
                page = browser.new_page(viewport={"width": viewport_width, "height": viewport_height})
                page.goto(html_abs_path.as_uri(), wait_until="load")
                
                # Wait for initial content to load
                page.wait_for_timeout(1000)
                
                # Wait for any charts or dynamic content to render
                try:
                    # Wait for common chart elements to be visible
                    page.wait_for_selector('canvas, svg, .chart, .pie-chart, .status-badge', timeout=5000)
                except:
                    # If no charts found, continue anyway
                    pass
                
                # Additional wait for any animations or dynamic content
                page.wait_for_timeout(2000)
                
                # Get actual page dimensions for full page capture
                if full_page:
                    # Get the actual content dimensions
                    page_width = page.evaluate("() => Math.max(document.documentElement.scrollWidth, document.body.scrollWidth)")
                    page_height = page.evaluate("() => Math.max(document.documentElement.scrollHeight, document.body.scrollHeight)")
                    
                    print(f"[DEBUG] Page dimensions: {page_width}x{page_height} pixels")
                    
                    # Ensure minimum dimensions
                    page_width = max(page_width, viewport_width)
                    page_height = max(page_height, viewport_height)
                    
                    # Update viewport to match content
                    page.set_viewport_size({"width": page_width, "height": page_height})
                    
                    # Wait a bit more for layout to settle
                    page.wait_for_timeout(1000)
                
                # Take screenshot with full page option
                screenshot_bytes = page.screenshot(full_page=full_page, type='png')
                browser.close()
                
                # Convert to PIL Image
                if PIL_AVAILABLE:
                    from io import BytesIO
                    img = PILImage.open(BytesIO(screenshot_bytes))
                    print(f"[DEBUG] Screenshot captured: {img.size[0]}x{img.size[1]} pixels")
                    return img
                else:
                    # If PIL not available, return None
                    return None
                    
    except Exception as e:
        print(f"[WARN] Playwright HTML to image conversion failed for {html_abs_path}: {e}")
        return None

def create_html_preview_image(html_abs_path: Path, max_width: int = 500, max_height: int = 400, full_page: bool = True):
    """Create a preview image from HTML file for PDF display.
    Returns a ReportLab Image object ready for PDF insertion.
    
    Args:
        html_abs_path: Path to HTML file
        max_width: Maximum width for PDF display
        max_height: Maximum height for PDF display
        full_page: Whether to capture full page (True) or just viewport (False)
    """
    try:
        # Convert HTML to PIL Image with full page capture
        pil_img = html_to_image_for_pdf(html_abs_path, max_width, max_height, full_page=full_page)
        
        if pil_img is None:
            # Fallback: create a placeholder image
            if PIL_AVAILABLE:
                pil_img = PILImage.new("RGB", (max_width, max_height), color=(245, 247, 250))
                draw = ImageDraw.Draw(pil_img)
                try:
                    font = ImageFont.load_default()
                except Exception:
                    font = None
                
                # Draw placeholder text
                text = "HTML Preview"
                filename = html_abs_path.name
                draw.text((20, max_height // 2 - 20), text, fill=(64, 64, 64), font=font)
                draw.text((20, max_height // 2 + 10), filename[:50], fill=(96, 96, 96), font=font)
            else:
                return None
        
        # Get original dimensions
        original_width, original_height = pil_img.size
        print(f"[DEBUG] HTML image captured: {original_width}x{original_height} pixels")
        
        # Calculate scaling to fit PDF dimensions while maintaining aspect ratio
        width_ratio = max_width / original_width
        height_ratio = max_height / original_height
        scale_ratio = min(width_ratio, height_ratio)
        
        # Ensure we don't scale up (only scale down if needed)
        if scale_ratio > 1:
            scale_ratio = 1
        
        new_width = int(original_width * scale_ratio)
        new_height = int(original_height * scale_ratio)
        
        print(f"[DEBUG] Scaled to PDF dimensions: {new_width}x{new_height} points")
        
        # Resize image if scaling is needed
        if scale_ratio != 1:
            pil_img = pil_img.resize((new_width, new_height), PILImage.Resampling.LANCZOS)
        
        # Convert to RGB if necessary
        if pil_img.mode in ('RGBA', 'LA', 'P'):
            rgb_img = PILImage.new('RGB', pil_img.size, (255, 255, 255))
            if pil_img.mode == 'P':
                pil_img = pil_img.convert('RGBA')
            rgb_img.paste(pil_img, mask=pil_img.split()[-1] if pil_img.mode in ('RGBA', 'LA') else None)
            pil_img = rgb_img
        
        # Save to temporary file and create ReportLab Image
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_img:
            pil_img.save(temp_img.name, format='JPEG', quality=90, optimize=True, dpi=(150, 150))
            reportlab_img = ReportLabImage(temp_img.name, width=new_width, height=new_height)
            
            # Clean up temp file after ReportLab loads it
            try:
                os.unlink(temp_img.name)
            except:
                pass
                
            return reportlab_img
            
    except Exception as e:
        print(f"[ERROR] Failed to create HTML preview image for {html_abs_path}: {e}")
        return None

def get_thumbnail_info():
    """Get information about thumbnail cache usage.
    
    NEW STRUCTURE: results/YYYYMMDD_HHMMSS/FeatureName/TestCaseID/.thumbnails/file_hash.png
    """
    try:
        total_files = 0
        total_size = 0
        folders = []
        
        # Scan for .thumbnails folders in the new structure
        for thumb_folder in RESULTS_DIR.rglob(".thumbnails"):
            try:
                # Check if this is in the correct location
                # Should be: results/YYYYMMDD_HHMMSS/FeatureName/TestCaseID/.thumbnails/
                parent_path = thumb_folder.parent
                if parent_path.name == ".thumbnails":
                    # Skip old centralized structure
                    continue
                
                # Check if parent is a test case folder
                grandparent = parent_path.parent
                if grandparent and grandparent.parent:
                    # Should be: results/YYYYMMDD_HHMMSS/FeatureName/TestCaseID/.thumbnails/
                    # Check if grandparent.parent is timestamp folder
                    timestamp_folder = grandparent.parent
                    if timestamp_folder.name and any(char.isdigit() for char in timestamp_folder.name):
                        # This is correct structure, count files
                        folder_info = f"{timestamp_folder.name}/{grandparent.name}/{parent_path.name}"
                        folders.append(folder_info)
                        
                        # Count files in this .thumbnails folder
                        for file_item in thumb_folder.iterdir():
                            if file_item.is_file() and file_item.suffix == '.png':
                                total_files += 1
                                total_size += file_item.stat().st_size
            except Exception as e:
                print(f"[WARN] Error scanning thumbnail folder {thumb_folder}: {e}")
        
        cache_size_mb = total_size / (1024 * 1024)
        
        return {
            "total_thumbnails": total_files,
            "cache_size_mb": round(cache_size_mb, 2),
            "folders": sorted(folders),
            "structure": "NEW: TestCaseID/.thumbnails/ in each test case folder"
        }
    except Exception as e:
        print(f"[ERROR] Failed to get thumbnail info: {e}")
        return {"error": str(e)}

@app.route('/api/thumbnail_info')
def api_thumbnail_info():
    """API endpoint to get thumbnail cache information."""
    return jsonify(get_thumbnail_info())

@app.route('/api/thumbnail_status')
def api_thumbnail_status():
    """API endpoint to get comprehensive thumbnail status including cleanup info."""
    cache_info = get_thumbnail_info()
    
    # Check for old structure
    thumb_root = RESULTS_DIR / ".thumbnails"
    old_files_count = 0
    old_dirs_count = 0
    
    if thumb_root.exists():
        for item in thumb_root.iterdir():
            if item.is_file() and item.suffix == '.png':
                if '_' in item.stem:
                    old_files_count += 1
            elif item.is_dir():
                dir_name = item.name
                if not (dir_name.replace('_', '').replace('-', '').isdigit() or 
                       any(char.isdigit() for char in dir_name)):
                    old_dirs_count += 1
    
    return jsonify({
        "cache_info": cache_info,
        "old_structure": {
            "old_files": old_files_count,
            "old_directories": old_dirs_count,
            "needs_cleanup": old_files_count > 0 or old_dirs_count > 0
        },
        "recommendations": {
            "cleanup_needed": old_files_count > 0 or old_dirs_count > 0,
            "message": f"Found {old_files_count} old files and {old_dirs_count} old directories that should be cleaned up" if (old_files_count > 0 or old_dirs_count > 0) else "No cleanup needed"
        }
    })

if __name__ == "__main__":
    print("ðŸš€ Starting Dashboard Report Server...")
    print(f"ðŸ“ Project Root: {PROJECT_ROOT}")
    print(f"ðŸ“Š Results Directory: {RESULTS_DIR}")
    
    # Show results directory discovery status
    print("\n" + "="*60)
    print("RESULTS DIRECTORY DISCOVERY")
    print("="*60)
    if RESULTS_DIR.exists():
        # Count valid timestamp folders
        timestamp_dirs = [d for d in RESULTS_DIR.iterdir() 
                         if d.is_dir() and is_valid_timestamp_folder(d.name)]
        
        print(f"âœ… Results directory successfully discovered")
        print(f"ðŸ“‚ Path: {RESULTS_DIR}")
        print(f"ðŸ“Š Contains {len(timestamp_dirs)} valid test run folders")
        
        if timestamp_dirs:
            # Show latest 3 runs
            latest_runs = sorted(timestamp_dirs, key=lambda d: d.name, reverse=True)[:3]
            print(f"ðŸ”„ Latest runs:")
            for run in latest_runs:
                run_features = [d for d in run.iterdir() if d.is_dir()]
                print(f"   â€¢ {run.name} ({len(run_features)} features)")
        else:
            print("âš ï¸ No test run data found in results directory")
            print("   Place test results in YYYYMMDD-HHMMSS format folders")
    else:
        print(f"âŒ Results directory not accessible: {RESULTS_DIR}")
    
    print("\nðŸ’¡ Configuration options:")
    print("   â€¢ Set environment variable RESULTS_DIR to override auto-discovery")
    print("   â€¢ Place any project with 'results' folder under project root")
    print("   â€¢ Results folder should contain timestamp folders (YYYYMMDD-HHMMSS)")
    print("="*60)
    
    # Verify font settings
    verify_font_settings()
    
    # Ensure Thai fonts are registered for ReportLab
    print("\n" + "="*60)
    print("THAI FONT SETUP")
    print("="*60)
    success = ensure_thai_fonts()
    print(f"Thai font setup result: {success}")
    print("="*60)
    
    # Check thumbnail capabilities
    print("\n" + "="*60)
    print("THUMBNAIL CAPABILITIES")
    print("="*60)
    if PLAYWRIGHT_AVAILABLE:
        print("âœ… Playwright: Available for high-quality HTML thumbnails")
    else:
        print("âŒ Playwright: Not available")
        print("   Install with: pip install playwright && playwright install chromium")
    
    if PIL_AVAILABLE:
        print("âœ… PIL/Pillow: Available for fallback thumbnails")
    else:
        print("âŒ PIL/Pillow: Not available")
        print("   Install with: pip install Pillow")
    
    if THUMBNAIL_CAPABLE:
        print("âœ… Overall: Thumbnail generation is available")
    else:
        print("âŒ Overall: No thumbnail generation capability")
        print("   Install either Playwright or PIL/Pillow")
    
    print("="*60)
    
    # Ensure thumbnail directory exists
    if THUMBNAIL_CAPABLE:
        # REMOVED: No need to create root thumbnail directory
        # Thumbnails will be created on-demand in TestCaseID/.thumbnails/ folders
        print(f"ðŸ“¸ Thumbnail system ready")
        print(f"ðŸ“ Thumbnails will be organized by test case folder structure")
        print(f"   NEW STRUCTURE: results/YYYYMMDD_HHMMSS/FeatureName/TestCaseID/.thumbnails/file_hash.png")
        
        # Test structured thumbnail creation
        try:
            test_html_path = RESULTS_DIR / "test_example.html"
            test_thumb_path = _get_thumbnail_path(test_html_path)
            print(f"ðŸ” Test thumbnail path structure: {test_thumb_path}")
            print(f"   This shows how thumbnails will be organized")
        except Exception as e:
            print(f"âš ï¸ Could not demonstrate thumbnail structure: {e}")
        
        # Show existing thumbnail cache info
        cache_info = get_thumbnail_info()
        if cache_info.get("total_thumbnails", 0) > 0:
            print(f"ðŸ“Š Existing thumbnail cache: {cache_info['total_thumbnails']} files, {cache_info['cache_size_mb']} MB")
            if cache_info.get("folders"):
                print(f"ðŸ“‚ Cache folders: {', '.join(cache_info['folders'][:5])}{'...' if len(cache_info['folders']) > 5 else ''}")
        else:
            print(f"ðŸ“Š No existing thumbnail cache found")
    
    print("="*60)
    
    print("\nðŸŒ Starting web server...")
    print("ðŸ“± Dashboard will be available at: http://127.0.0.1:5000")
    
    # Open browser after a short delay
    Timer(1.5, open_browser).start()
    
    # Start the Flask app
    app.run(debug=False, host='0.0.0.0', port=5000)
